{"meta":{"title":"Jim Tang's blog","subtitle":"","description":"","author":"Jim Tang","url":"https://txiaozhe.github.io","root":"/"},"posts":[{"tags":[{"name":"Job","slug":"Job","permalink":"https://txiaozhe.github.io/tags/Job/"},{"name":"Live","slug":"Live","permalink":"https://txiaozhe.github.io/tags/Live/"},{"name":"BigData","slug":"BigData","permalink":"https://txiaozhe.github.io/tags/BigData/"}],"title":"复盘1：直播大数据采集（一期）","date":"2019/12/15","text":"这是2017年10月到2018年10月在全民直播期间的一个项目，因为在直播公司的缘故，所以会涉及很多直播相关的业务。当时有几家做的比较好的直播平台，比如斗鱼、虎牙、熊猫、战旗、全民等，直播内容都以游戏、才艺表演为主，直播受众广，每天产生的数据流量巨大，公司为此启动一个新项目，采集全平台直播数据，并经大数据技术清洗统计后为直播行业提供数据化运营解决方案。 加入全民直播的时候正值刚毕业不久，从河北来到杭州，机缘巧合就入职了全民，接手了这一项目，因为当时负责项目开发的工程师即将离职，因此我也算紧急受命。对那时候的我来说，这个项目算是相对难度最高的，为什么这样说呢？首先因为我本身并不是计算机科班出身，再加上在学校自学的经历，虽也接触过不少的技术，但都不深入，所以当初次接触到这种成体系的项目时就显得有些局促了。当然，项目本身也算是难度比较大的，由于是后期接手的缘故，所以也就没有参与初期技术方案的设计，但其中的细节还是值得考虑的。本文即是复盘当时项目的业务及技术细节，结合接手项目后及二期改进所做的工作，对当时碰到的问题及技术方案设计进行整理和思考。 简单介绍一下业务如果你看过游戏直播（如果没看过现在可以打开看看，比如斗鱼、虎牙）就会比较熟悉，当打开一些热门网红的直播主页时会看到很多内容，首先是源源不断刷过整个屏幕的弹幕，还有一些粉丝送给主播的礼物（比如火箭），这些都算是动态数据，而且从全网来看数据量巨大。其次还有很多相对静态的内容，比如主播名称、热度、关注度等相关信息。对于做直播业务的公司来说，这当然是有价值的。因此我们要做的事情就是把这些动态和静态的数据源源不断地从网络上抓取下来，并通过一些大数据手段进行清洗和计算，最后得到一个全网主播的动态信息汇总平台，并向行业内相关人士或机构提供大数据咨询服务。 面临的问题从技术层面思考这个事情，其实简单来说我们要做的就是通过一些手段把上面说的各种静态和动态数据从各个直播平台上抓取下来（说白了就是爬虫），然后通过一个大数据清洗和计算流程汇总得到业务所需的形态，最后通过网页或 app 的形式把数据展示给用户。 业务目标清楚了，接下来从技术角度梳理一下做这个事情可能会碰到什么问题： 直播平台众多，各平台无兼容性：当时正值娱乐直播业务的红海期，各种直播平台相互竞争，首期决定采集的平台有斗鱼、虎牙、龙珠、战旗、触手、熊猫、全民。 涉及数据类别有多种，协议层适配和数据清洗会很复杂：首期决定采集的直播数据有弹幕、礼物、主播个人信息、主播热度及关注度 可能会遭到平台方的封锁：毕竟是爬虫，你懂的（不过不像现在，当时还没有这么严重的法律风险）。 从直观上看数据量可能会很大：最终从事实上来看确实很大，数据的采集、计算、存储、读取都需要考虑这方面因素。 技术选型及解决方案语言：Node.js / Go（二期升级时采用） 数据库、缓存及静态存储：MySQL、Redis、阿里云 OSS 数据搜索服务：Elasticsearch 服务器：阿里云 ECS 流数据池子：阿里云日志服务 前后端：Express / Koa / Vue 冷数据存储：阿里云 ODPS 服务器监控：Grafana / Alinode 部署方案：GitLab CI / Ansible 大数据清洗和计算：阿里云实时计算 平台及数据兼容层前面提到，首期业务决定采集斗鱼虎牙等7个平台的数据，深入看一下这几个平台的数据采集方式（由于当时有专门的团队已经做过相关工作，因此假设此时已经得到各个平台可用的 api 及接口访问权限，全民属于自有平台，接口信息也可看作已知）会发现每个平台都是不一样的，从接口协议层面看，因数据类别不同涉及到的协议有 TCP、WebSocket 以及 Http，动态数据如弹幕和礼物因为实时性比较强所以一般都是用 TCP 和 WebSocket 传输，当然也有比较奇葩的用 Http 的（比如触手）。静态数据如主播个人信息、关注度等则基本都是 Http 接口，当然也有不提供特定接口而直接从后端渲染的，不过本质上没有太大区别，只是后期处理上会稍显繁琐。 为了解决上述问题，比较通用的做法是在所有平台之上建立兼容层，将需要采集的数据分为 弹幕/礼物、主播信息、热度、关注数四大类，并抽象出其中的接口及事件。 如对于弹幕/礼物数据的采集模块来说会抽象出如下接口和事件： init：按平台需求进行鉴权、Socket 连接及开启数据监听（针对 TCP 和 WebSocket）、初始化轮询请求（针对Http）以及请求一些附加的平台数据操作。 destroy：断开连接停止采集。 connect 事件：监听连接事件。 data 事件：接收请求到的数据，并进行相应的后续处理。 error 事件：等待超时或出现错误，则停止采集或进行重连。 close 事件：正常关闭操作。 在兼容层的上层，则按照采集到的数据的不同格式及类型建立 ETL 层对数据进行清洗得到平台通用的数据格式，架构示意图如下： 对于主播信息、热度、关注数类别的数据处理方式也是类似，针对平台差异抽象出不同平台的接口共性，并在使用时按平台调用。 采集集群如果打开一些热门网红的直播间会发现在其直播期间，屏幕上会飘过海量的弹幕和礼物，从全平台来看，这些数据的量是非常大的，在项目维护期间我也曾做过粗略的统计，发现每天流过系统的数据量达到 400 - 600G，也就是说每天采集到的数据能装满一个 500G 的硬盘，这还只是清洗过后的，且不计图片、头像等数据，如果按照清洗前的量将大大超出这个值。要实现将这个量级的数据实时地从网络上抓取下来并集中清洗，势必需要多台服务器配合组成集群，将负载分配到每一个节点，并能根据采集量动态伸缩集群容量，达到业务和成本的平衡。 集群架构设计如下图： 任务系统要采用集群化采集方案，则必然设计一套任务系统，将采集任务细化、标准化。这里还会涉及到另一个数据需求，即直播间开关播状态。因为当时并没有获取直播间状态的方法，因此采用列表对比的方式获得相对准确的直播间开关播状态，原理简单来说就是定时拉取平台的直播间列表并存储到 DB 中，等下一次再拿到列表时与 DB 中的列表对比得出开关播状态。如 DB 中已有 A、B、C 三个直播间状态为开播，下一次拿到的列表为 A、B ，则此时判定 C 直播间关播，以此类推。开关播状态除了本身是数据需求的一部分以外，还是采集节点采集数据与否的依据，因为观察发现，当主播关播时，直播间将没有或只有少量弹幕礼物数据刷过，这一部分数据可以忽略不计，为此当主播关播时关闭采集可以节省成本。 使用一台单独的服务器拉取各个平台主播列表作为任务源，拉取时间间隔为 1 分钟，主播列表中会包含主播详细信息并将该信息存到一张单独的表中。拉取到的列表按不同平台分批发送至调度中心，由调度中心来完成直播间状态的比对，并将该信息更新到 DB 中。 调度中心调度中心会负责两方面的任务，一个是上面提到的，接受来自任务源的任务队列，并与 DB 中已有的任务进行比对得出需要更新的直播间状态。另一个则是分配任务。 采集集群会在启动时与调度中心取得长连接，采集节点会告知本机的局域网 IP 地址（集群中所有节点都在同一个局域网内），并将本机采集负载（采集任务数）通过 RPC 接口的方式暴露给调度中心，保持长连接意味着采集节点的状态变化可以实时地被调度中心感知到，调度中心依据此维护一个可用的采集节点列表（即 IP 列表），并能通过 RPC 机制实时地获取每个节点的负载。当调度中心收到来自任务源的任务列表时会比对得出所有需要更新采集状态（开启或停止采集）的任务，如遇到需要新开采集的任务时，会在可用的采集节点列表中选取一个负载最小的节点，将该节点 IP 与该任务绑定，赋予任务状态为 ACCEPT，表示该任务为新接收的任务，并将该任务存至任务列表。同时，若调度中心感知到某节点出现异常，比如断开连接，则调度中心会将任务列表中标记给该节点 IP 的所有任务取出，重复上述步骤，选取一个负载最小的节点，将该任务分配给该节点，若出现问题的是某任务，则调度中心会为其重新分配一个节点，该任务会被该节点发现并重新开启采集。这样一来，所有任务将在整个采集集群中动态平均分配，并在节点异常时及时回收任务再分配，以此平衡所有节点的负载，并将节点异常带来的数据损失降到最低。 集群采集集群的工作即按平台差异以不同的方式从各个直播平台源源不断地拉取数据，集群中每一个节点都是等价的，集群规模也可以动态伸缩。集群节点服务主要以两部分组成：Manager（任务管理器）和 Bee（采集器）。Manager 是集群节点的主体，一方面在节点启动时，Manager 会与调度中心连接并实时同步 IP 信息和负载水平，另一方面，因调度中心已实时地将各个需要开启和关闭的任务同步至任务列表中，Manager 会定时到任务列表中领取与本机 IP 相匹配的任务进行相关操作，如开启或关闭采集。采集的主体即 Bee（命名取自小蜜蜂采集花蜜），当 Manager 拿到一个需要开启采集的任务时，会初始化一个 Bee 实例，Bee 初始化时会按照指定平台调用实现了特定接口的客户端与平台方取得连接，并将列表中任务状态改为 RUNNING，Bee 会接受来自平台的数据流，并调用特定的方法对数据流进行解析、计算、清洗，最终以统一的格式写入阿里云日志服务。也就是说，一个采集结点中只有一个 Manager，但该 Manager 会管理多个 Bee 实例。当某个 Bee 实例出现异常，比如与平台断开连接，则 Bee 会停止采集并将该任务标记为 FAILED，后续该任务会被调度中心发现并重新分配。同理，当 Manager 拿到一个待关闭任务时，则将该任务标记为 CLOES，后续该任务会进入关闭流程，关闭与平台的连接，并从任务列表中清除。 初期集群规模为 40 台阿里云 ECS 服务器，并通过 Ansible 统一部署与管理。每个集群上的任务数和资源占用水平都可以通过 Grafana 查看。从最终结果看来，全平台高峰期同时开播的直播间最高为 10 万个，也就是峰值任务约为 2500 个/台，LogHub 流数据为 400 - 600 G/天，这都在系统各个部件的承受范围内。且所有服务器都通过 Alinode 进行实时监控。 规避风控前面已经提到过，该采集任务可能会碰到平台封锁的问题，事实上也是如此，且在业务后期平台封锁问题已成为整个服务的最大瓶颈。平台的封锁主要集中在任务源处，若直播平台封锁任务列表的拉取，会导致采集任务无法更新，最终导致数据与实际数据差距巨大，造成业务上数据不可信。因此解决该问题一直是最重要的任务。当时采取了以下几种方式： 规避平台风控规则：平台的封锁规则一般都和拉取频率有关，若拉取频率超过平台规定的阈值，会导致封锁。因此在拉取列表时尽量规避，该方法成本低，虽造成任务更新不及时，但也算保全了一部分数据，总体来看效果一般。 通过 CDN 节点拉取数据：直播平台一般都会有大量 CDN 节点，因此可以借助 CDN 进行数据拉取。但实施后发现 CDN 节点部署位置较分散，甚至有很多部署在国外，虽说这样做规避了一部分封锁的风险，但由于拉取速度太慢，总体效果不好，最终放弃该方案。 代理：终极解决方案，通过专门的爬虫代理服务器对目标平台进行请求，最终实现了较平稳的数据流输出。唯一的缺点是该方案成本较高。 计算本系统中采集到的所有数据，除了主播信息、主播关注度、图片等少量且静态的数据存储在 MySQL 和 OSS 以外，其他动态数据都被存至阿里云 LogHub 日志服务中，主要原因是 LogHub 成本极低，且能在阿里云平台上动态查询检索数据，又由于 LogHub 与阿里云实时计算已实现了无缝对接，所以将其作为消息队列使用，业务过程中曾经考虑使用 Kafka 作为消息队列，但由于部署成本较高，且若使用 Kafka，则后续实时计算和流计算都需考虑自行部署（当时是这样），因此一直坚持使用 LogHub。 由于大数据计算部分是由另外一名同学专门负责的，因此我当时也没有参与相关操作，这里不再赘述。由于经过计算后的数据量仍然极大，以此该同学已考虑到将所有结果数据按照时间（大部分数据区分到月份，部分数据区分到日期）分表存放，以便于后续服务读取。 服务业务的最终目标是将上述采集、清洗计算得出的数据以数据平台的方式展示给用户，因此最终的产品形态是一个网页，主要由 Koa + Vue 实现，其中涉及到数据的读取，由于数据量较大，因此前期会将一部分数据按照热度进行缓存以提高读取效率。因该服务也是另一位同学专门负责，其中涉及的技术主要有 Web 服务、用户系统、数据库 CRUD、API 接口等，与一般 Web 服务没有太大差异，因此在此不再赘述。 还没完由于业务上的需求以及技术迭代，该项目进行了二期改造。其中会涉及到更多的技术细节，如调度中心的单点问题、任务分配机制有没有更好的方案、如何提高本地数据清洗效率等等。本文即较完整地阐述了直播大数据采集一期项目的技术实现细节，原本打算将二期也一起讲述，但由于涉及细节太多，目前篇幅已过长，因此决定将二期内容放到下一篇文章详细讲述。 本人一直坚持，技术没有好坏。而技术也一定与业务的平衡与取舍。如有不明确或错误的地方欢迎留言或指出~不喜勿喷 :)","permalink":"https://txiaozhe.github.io/2019/12/15/live-data-fetch/","photos":[]},{"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://txiaozhe.github.io/tags/JavaScript/"},{"name":"JerryScript","slug":"JerryScript","permalink":"https://txiaozhe.github.io/tags/JerryScript/"}],"title":"JavaScript in IoT","date":"2019/12/13","text":"今天分享的内容是 “JavaScript in IoT”，在低端设备上运行 JavaScript，这与我上一段工作经历有关，之前我在一家做语音交互和 IoT 的公司，负责 IoT 设备端服务的基础架构，简单来说就是运行在 IoT 设备上的一个服务，与 IoT 云端交互用的。当时我用的 IoT 设备主要是几款智能音箱，上面有搭载有嵌入式开发板，系统资源的话内存基本都在100MB 左右，这相对我们日常开发用的电脑或服务器来说可以算是捉襟见肘的，我负责的内容就是用 js 语言在这个板子上面做一个与云端交互的模块，那这种低端设备上如果运行日常用的 Node.js 肯定是跑不动的，所以我们为了实现在 IoT 设备运行 js 并用 js 写程序，特地开发了一套针对 IoT 场景的 js 运行时，叫 ShadowNode。对我来说最开始的时候我只是这个项目里面的一个贡献者，后面跟团队接触多了，也就逐渐地被吸引以至于最后直接加入团队，后面就用这个工具进行 IoT 的研发，慢慢地也对整个体系有了更多的了解。 IoT The Internet of Things (IoT) is a system of interrelated computing devices, mechanical and digital machines, objects, animals or people that are provided with unique identifiers (UIDs) and the ability to transfer data over a network without requiring human-to-human or human-to-computer interaction 什么是 IoT， 全称 Internet of things，也就是物联网。这是 wiki 上对 IoT 的解释，IoT 是一种由具有唯一 id 的计算设备、机械、数字设备、物体、动物或人等关联起来的系统，并且可以通过网络传输数据，无需人与人或人与计算机交互，也就是所谓的万物互联。但目前为止我们日常所碰到的 IoT 设备见得比较多的还是各种灯、音响，比如米家有各种设备可以连入网络，我们之前就有自研的智能音箱，可以连接各种三方设备，并可以通过语音或手机控制。 为什么是 JavaScript首先对于程序员，肯定要考虑如何对 IoT 进行编程，或者说在嵌入式设备上写程序，我们可能比较了解的是用 c 或 C++ 语言进行编程 ，因为 IoT 设备中充斥着大量低端设备，这里说的低端设备指的是比如各种嵌入式芯片，RAM 或 ROM 或 flash 容量非常小，我们所知道的树莓派已经算是很高端的设备了，通常内存都在2G 以上，比如我们以前用的智能音箱上的内存基本都在100M左右，因此在这种设备上写程序，c/c++ 基本是标配。 但我们今天要讲的是用 JavaScript 在这种低端设备上编程。大家可能觉得我们疯了，因为都知道JavaScript是一种脚本语言，一直以来主要在前端里面用，后来被引用至服务器端也就是 Node.js。当时对我们来说最现实的需求就是，最开始我们的 IoT 服务都是用 js 写的，而且运行在比较高端的设备上，后来引入低端设备的时候发现如果不做底层的优化，那所有的业务都得重写。JavaScript作为一种脚本语言是解释执行的，其性能堪忧，而且也不是世界上最好的语言，但我们也知道，JavaScript拥有非常完善的社区生态和庞大的开发者群体，这是一个非常大的优势，其实用 C/C++ 编程相对来说门槛还是挺高的，但试想一下，如果一个前端开发者，只会 js 语言，原本只会写前端页面，但是现在能在简单学习了 IoT 设备相关 api 后就能动手开发嵌入式程序，想想是不是很酷，其实这也是我们的初衷，也就是利用 js 的生态和社区基础，降低嵌入式开发的门槛并助推推广 IoT 的发展。至于性能什么的，这是我们需要考虑的！ 而且我们也确实在低端设备上去运行 js 了，那我们是怎么做到的呢？ Node.js讲到JavaScript，必然要提到 Node.js，而且今天的主要内容也会跟 Node.js 有关。我们知道 Node.js 是在服务器端运行JavaScript的环境，类似于虚拟机。 V8/libuv是构成 Node.js 的两大核心组件，V8 原本是chrome 的 js 引擎，后来被引用到 Node.js 中，为 js 语言提供了解析和运行的环境，libuv 则是我们常说的 Node.js 异步非阻塞的来源，这里面也用到了很多系统级的api和资源。还有一些三方库用来为系统提供一些功能，比如openssl，crypto、zlib等等。 同样，在嵌入式设备上运行也可以采取类似的架构，因为本身也都是linux，比如需要一个可以在低端设备上运行的 js 解释和执行环境，然后也需要一些额外的支持用来提供异步i/o以及各种上面提到的加解密、网络通信等等操作 后来我们就找到了 JerryScript JerryScript JerryScript is the lightweight JavaScript engine intended to run on a very constrained devices such as microcontrollers: • Only few kilobytes of RAM available to the engine (&lt;64 KB RAM) • Constrained ROM space for the code of the engine (&lt;200 KB ROM) The engine supports on-device compilation, execution and provides access to peripherals from JavaScript. JerryScript 是一款由三星研发的用于 IoT 设备的 js 虚拟机 这是jerry 官网首页的一句话简介：JerryScript 是一个为 IoT 而开发的轻量级 JavaScript 引擎，可以运行在资源十分受限的设备上，支持在设备上解释、执行 JavaScript 以及对外围设备的访问，内存低于64KB，rom低于200KB，可以说对资源很苛刻了。 这个表展示了各种层次的设备的软硬件指标，JerryScript 就是针对下述 Low-end 也就是低端设备开发的。 Low-end Medium-end Smart phone RAM / ROM Tens of kb ~ 4MB Hundreds of MB GB+ Processor 1 Core 1 – 4 Core 4 Core+ OS RTOS Linux Android / iOS JerryScript 也可以看作是对 EcmaScript 标准的一个实现，目前支持到 es5的标准 Jerry 之所以能在低端设备上运行，因为其采用了非常紧凑的内存布局设计，对源码解释、运行过程、对象属性、值表示以及函数操作都做了针对节省内存的优化 比如：v8里面对 js 源码的解析会经过源码 –&gt; ast（抽象语法树）–&gt; 字节码，而 jerry 直接把 ast 那一步省略了，直接从源码解释成字节码。另外jerry还对字节码快照进行了优化，可以直接执行快照，甚至可以把快照存到rom里并直接从 rom 里执行快照，这样节省了源码解析的内存消耗与性能成本。 另外 jerry 对各种类型和值表示的内存布局也设计得相当紧凑，这极大地节省了内存，当然，极致的优化也会带来一些副作用，比如代码的执行效率会降低。 具体的就先不展开了，感兴趣的话大家可以去jerry官网看，感兴趣的同学也可以把源码 down 下来，本地编译一下，或者也可以按照文档的说明用这个引擎把你的 js 代码嵌到 C 代码里运行，不过直接在 mac 上编译会碰到一些问题，在此我也准备了一个 docker 容器，我在里面已经准备好了所有编译 Jerry 所需的环境，并发布到了公共的 docker hub，感兴趣的同学可以 pull 下来试一试。 IoT.js前面说了，只有一个 js 环境并不能搞定一切，一个裸的 js 虚拟机还是太局限了，因此还需要一些额外的支持来提供完善的环境，幸好三星也同样做了这样的支持。为此三星还开发出了 Libtuv。 Libtuv，是对标 Node.js 所用的 libuv 的嵌入式版本，也是三星开发，为整个运行的环境中提供异步I/O的能力。而 IoT.js，就是一个完整的能在嵌入式设备上运行的 js 运行时， Node.js 支持的特性它也基本支持，比如异步I/O，事件循环，以及各种原生的api。 其实整个架构体系和我们刚刚看到的 Node.js 是差不多的，只不过底层支撑的模块不一样，同时，为了能更好地运行在 IoT 环境里，IoT.js 也根据嵌入式设备的场景做了一些额外的支持，比如 mqtt，还有一些对嵌入式设备的操作支持。 讲到这里，好像没什么事可做了，因为三星已经把该做的都做了，IoT.js 做的支持也足够，什么异步 i/o， IoT 适配都做了，对内存的优化也做到了几十k的变态级别，但这真的就是我们想要的吗？ 我们看看 IoT.js 有什么问题？ 为了把内存控制在几十k的级别，IoT.js 可谓是费尽心机，这也导致了 IoT.js 不支持很多好用的特性，比如不支持类，promise，甚至不支持 debug，出错的时候无法输出完整的错误栈，这就很头疼了。不过，当时我们业务上用的设备也没那么苛刻，基本都是内存在 100MB 左右的中端设备，而且也为了顺应社区和生态的需求，我们也希望我们用的运行时能支持更多的特性，也能更加容易使用，所以我们就在 IoT.js 的基础上开发了 ShadowNode。 ShadowNodeShadowNode 是基于 IoT.js 一个运行时，只不过面向的目标设备不一样，IoT.js 面向极低端的设备，而 ShadowNode 则是面向中端设备，因此两者并不冲突。我们当时的工作主要有几个，一个是对于一些实用特性的支持，比如错误栈、更完善的 js 语言特性等，还有一个就是支持更多的 Node.js api 以及社区的构建。 ShadowNode 的原生支持目前 ShadowNode 原生支持的特性有 Class，Promise，以及 debug 的错误栈输出，N-API等等，以及更完善的兼容 Node.js 的 api，不过目前一些特性在 JerryScript 中也逐渐被支持了，生态总是越来越完善。 mqtt &amp; dbusmqtt 其实是一个面向 IoT 场景的通信协议，基于 TCP，同样的，协议的设计也十分精简和“节约”，有点类似于我们平常在做 TCP 通信的时候自己定义的封包规则，只不过里面还定义了很多校验数据的规则，总体来说也是为 IoT 特殊场景而优化的。至于 D-Bus，可能做过 Linux 开发的同学会更加熟悉，这是一种高效的 IPC 机制，感兴趣的同学可以自行查阅资料。 支持的平台目前 ShadowNode 支持以下平台： Linux / (Docker) MacOS Raspberry Pi Kamino18 / (Amlogic/a113) / Hi3561 NuttX / TizenRT ShadowNode 在 Linux 和 MacOS 中能被友好地支持（不过在 mac 上编译会碰到一些问题，比如 dbus，可以参考 issues 解决），目前 windows 还不支持。感兴趣的同学也可以尝试在 docker 容器中试着编译运行，我之前尝试过，也碰到过一些问题。Raspberry Pi 也是支持的，不过大多数树莓派属于高端设备了，使用 ShadowNode 的意义并不大。Kamino18 / (Amlogic/a113) / Hi3561 是我之前在工作中用到过的三款开发板，其中 Kamino18 是rokid 自研的，Amlogic/a113 是晶晨半导体的，Hi3561来自华为海思。至于 NuttX / TizenRT，其实我也不太懂，是 ShadowNode 主页看来的，貌似是两款 rtos，感兴趣的同学可以自行搜索相关资料。 NPM目前对于 ShadowNode 来说，原生的 npm 还不支持，其实支持起来是不难的，而且我们当时的期望是兼容整个 Node.js 体系的，只不过这里面有一些现实原因，比如兼容性、性能等等，这也是我一直认为比较遗憾的地方。 我们在系统定义了一个全局的 node_modules，使运行时默认寻址，这样就能减少包导入的消耗。因为我们还是希望以此去推动社区发展的，并也希望能通过社区助力整个生态的成长，因此包管理机制怎么也得有一个，目前完全开放的 npm 使得任何人都可以随时写一个 Node.js 包发到 npm 平台上，这也就会造成包管理混乱、代码质量不可控等问题。我当时所设想的是一种半私有的包管理机制，在兼容 Node.js 端和设备端的同时，鼓励开发者把现有的 Node.js 包改造成能在设备上良好运行的样子，而且可以发到我们的平台上，当然，我们会加强审核，比如需要通过我们的性能测试以及代码 review。 硬件接口ShadowNode 也同样支持一些硬件接口，比如 ADC/BLE 等等，这个的话有兴趣的同学可以自行看资料。 社区和商业化有了工具，必然是要做一些事情的，除了当时我负责的 IoT 设备端服务外，我们还基于 js 和 Linux 打造了一款面向 IoT、智能设备以及语音交互的操作系统 YodaOS，并定义了一套语音交互应用开发的范式VUI和标准，而且后面我们也期望开发我们自己的 js rtos – rt-node，关于这些内容这里就不再做详细介绍了，原因的话一方面这几块内容我并没有直接参与，所以对里面一些细节也不很了解，另一方面 YodaOS 相关的内容与当时公司的业务太紧密相关，而且也区分商业版和社区版，所以这里也不适合详细介绍，感兴趣的同学可以自行去搜索相关内容。 相关链接： IoT wikipedia JerryScript JerryScript GitHub JerryScript Env by Docker IoT.js IoT.js GitHub ShadowNode GitHub YodaOS GitHub yoda.js GitHub rt-node GitHub Thanks :) @eshine @yorkie @lolbig","permalink":"https://txiaozhe.github.io/2019/12/13/javascript-in-iot/","photos":["/images/javascript-in-iot.jpg"]},{"tags":[{"name":"Life","slug":"Life","permalink":"https://txiaozhe.github.io/tags/Life/"},{"name":"Job","slug":"Job","permalink":"https://txiaozhe.github.io/tags/Job/"}],"title":"写在 2019 的结尾","date":"2019/12/05","text":"2019 眼看着就要过去了，匆匆忙忙一年又一年，回望即将过去的2019，失落地发现好像这一年充满了遗憾，但总的来说过去的一年还是有所收获的！ 两年前的十月，我离开了待了四年多的大学以及让人爱不起来也恨不起来的那个城市，带着一些不舍与无奈、也有信心和期待，还有20本书和债务，来到杭州，入职了一家看上去挺有意思的公司。时间可过得真快呐，一年前的十月，我就离开了那家现在看起来就是在压榨我的公司，当然，离开的原因并不是网上流传的那种95后一言不合就炒了老板，个中缘由，网上查查就知道了。 那个时候我总告诉自己无论在哪里，一定要心怀感恩，因为这样我才能在各种环境中找到我存在的价值以及我得到的收获。当时正值区块链的概念炒得热火朝天，不过现在也不算冷。于是我顺势进了一家区块链公司。嗯那家公司挺不错的，哪怕现在看起来也很好，办公地点在环境极好的西溪湿地（虽然现在已经不在那了），而且福利也不错。正值年底，杭州的冬天还是挺冷的，但是不久以后，更冷的互联网裁员潮就来了。那段时间真的过得战战兢兢的，年初的时候去了一趟北京，回来发现变天了，身边的同事莫名其妙地离开，从那时开始感受到无奈，虽然最后并没有被波及到，但总是心有余悸的。现在回忆起那段时间来，算是职业生涯里最 “休闲” 的一段时间了，当然并不是因为偷懒，大环境使然吧！在西溪湿地工作的那半年里，每当吃完午饭，同事们就三三两两地在西溪湿地里面散步，半年下来，竟把大部分区域都转遍了，我拍了各种各样的照片与风光，戏称自己是西溪湿地景区管理员，也算是一个收获吧！但更大的收获还是来自于社区，在参与社区事务的过程中，给社区贡献过代码和建议，也开始尝试去推动一些事情的发展，并逐渐建立了自己的社区理念，最重要的是认识了很多非常优秀的朋友。在社区里行走就像登山，每个人都热爱登山，一个接一个地往上走，你停不下来的，因为总有人在你后面，不要挡住人家。 后来，我还是离开了，可能还是坐不住！ 现在回过头去看这即将过去的2019年，其中最重要的事情应该算入职 Rokid 吧！准确地说是加入了一个非常优秀的团队，开始与原先的社区伙伴朝夕相处，也接触了新的领域–IoT。不过讲真，在 Rokid 工作压力还是相当大的，倒没有996，主要是在那里你会看到所有人都在往前走，你走不动了也没事，会有人推着你。那段时间甚至开始轻微地掉头发，吓得我赶紧买了霸王防脱，小心地呵护随时可能上移的发际线。但也从那时候开始从全局角度思考问题，开始为代码的健壮性做努力，也开始逐渐放下躁动不安的心，把心思放在手上做的那件事情。在社区的一些想法一再搁浅的情况下，我开始反思我的那些所谓自己的理念，有大佬跟我说过一句话：你是一个工程师，归根结底是要解决问题的。 可是好景不长，在 Rokid 将将4个月，我又要离开了。这也是从业以来最舍不得的一次离职了！哪怕现在想起来也充满了落寞，也许曾经是有留下的机会的，但是看不清，哪怕现在也看不清。在离职后的一次偶然的事情中要去一趟 Rokid 楼内，发现原先能随意进出的门禁如今也要登记询问才能出入。看着留下的人庆祝五周年，心里五味杂陈！跟一同离职的小伙伴聊起 Rokid，我说要说对 Rokid 的感情，恐怕我还没这个资格，我想，真正舍不得的一定是团队了吧！ 匆匆忙忙来来去去，这次也来不及心怀感恩了，莫名其妙地开始找工作，本以为可以坦然地等待新机会的，在待业一个月并发了一次高烧后，心态终于绷不住了。来到新的环境，却见到老的同事，兜兜转转终究还是要走到一起的，只能尴尬地相视而笑，这个世界可真小。 相信一切都是最好的选择！ 2019年，没去什么地方，北京、上海、南京，都是有事才去的。去了绍兴、宁波，还行。 2019年，没有完整地看完过一本书，明年要补上。 2019年，花了大半积蓄给自己置办了一件大礼物，也受到过很多质疑，但我想，能用钱取悦自己其实是最简单的，剩下的就是去努力挣钱。 2019年，没有像想象中的那样找到女朋友，目测已经基本放弃，开始本着佛系找女朋友的心态面对各种亲人长辈朋友的亲切问候和热心关怀。 2019年，即将再见！ 2020年，有所期待也不过度期待！","permalink":"https://txiaozhe.github.io/2019/12/05/end-2019/","photos":[]},{"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://txiaozhe.github.io/tags/JavaScript/"},{"name":"JerryScript","slug":"JerryScript","permalink":"https://txiaozhe.github.io/tags/JerryScript/"}],"title":"JerryScript 学习笔记","date":"2019/11/18","text":"这是 JerryScript 官网的一段简介： 简单翻译一下： JerryScript 是一个为 IoT 而开发的轻量级 JavaScript 引擎，可以运行在资源十分受限的设备上，比如： RAM 低于 64KB 的设备 ROM 低于 200KB 的设备 该引擎支持在设备上解释、执行 JavaScript 以及对外围设备的访问。 说白了 JerryScript 和我们日常用的 Chrome 和 Node.js 中的 V8 是一回事，是一个引擎，只不过 JerryScript 能运行在更加低端的设备上，如嵌入式设备。我们知道，JavaScript 作为一个脚本语言有其先天的缺陷，如解释执行的效率低下以及臃肿的堆内存的占用，哪怕 V8 的设计与实现已经做了大量的优化与改进，但距离能运行在 RAM 以 KB 为单位的设备上还差得很远。这不禁使人产生疑问，同样是对统一标准的实现，JerryScript 凭什么做到运行在 RAM 低于 64KB，ROM 低于 200KB 的设备上这种骚操作。本文是对 JerryScript 的官方文档 的翻译。 如上图，Parser(解析器) 和 VM(虚拟机) 是 JerryScript 的两个核心组件。一般来说 JerryScript 运行的基本流程，首先，Parser 将加载到的 JS 标准代码解析成具有特殊格式的字节码，然后由 VM 对字节码进行执行。 Parser在 JerryScript 里，Parser 被设计为 recursive descent parser（递归下降解析器），这样的解析器可以直接将标准 JS 代码转换成字节码而并不像 V8 那样会构建一个 AST。这里的实现依赖以下四个组件：Lexer（词法分析器）、 Scanner、Expression Parser（表达式解析器）以及 Statement Parser（语句解析器）。 Lexer将输入的代码字符串切分成标识符序列，其不仅可以按顺序向前扫描输入字符串，而且可以移动到任意位置。 ###Scanner 对输入的字符串进行预扫描并搜索特定字符，比如这一步可以确定出现 for 的地方代表了常规的循环还是 for-in 循环。 Expression Parser负责解析 JavaScript 表达式。 Statement Parser负责解析 JavaScript 语句。 上图展示了 Parser 中几个主要组件的相互作用，函数 parser_parse_source 对输入的 ES 源代码进行解析和编译，当遇到函数时，调用 parser_parse_function对代码进行递归操作，包括参数解析和上下文处理。解析之后，parser_post_processing 函数转储创建的操作码并返回一个 ecma_compiled_code_t * 指针，它指向已编译的字节码序列。 Byte-code与其他 JS 引擎的实现相比，JerryScript 实现了更加紧凑的字节码形式（CBC），和其他只关注性能的实现相比，一方面减少了字节码的内存消耗，同时又具有可观的性能。CBC 类似于 CISC 指令集，可为频繁的操作分配较短的指令。 许多指令表示多个原子操作，减少了字节码体积，这类似于一种数据压缩方法。 编译的字节码的内存布局 header 表示一个具有多个域的 cbc_compiled_code 结构，这些域包含了字节码的关键属性。 literial 部分是一个 ecma 值的数组，这些值包含了 ECMAScript 定义的数据类型，比如 string、number、function等等。该数组长度由 header 中的 literal_end 字段指定。 CBC instruction list 是一系列的字节码指令，他们代表编译后的代码。 字节码内存布局 每一个字节码都由 opcode 开头。常见指令的 opcode 为1字节，反之稀有指令的为2字节。稀有指令的第一个字节始终为零（CBC_EXT_OPCODE），第二个字节表示扩展操作码。 常见指令和稀有指令的名称分别以 CBC_ 和CBC_EXT_ 前缀开头。 由于可以定义 255个公共指令（不包括零值）和256个稀有指令，因此 opcode 的最大个数是 511，目前大约有215条常见指令和70条稀有指令可用。 在 CBC 中有3种字节码参数： byte argument（字节参数）：介于0~255之间的值，通常代表操作码操作调用的参数计数（函数、new、eval等） literal argument（字面量参数）：在header中介于0~literal_end（包含0）之间的整数索引的域 relative branch（相对分支参数）：长度为1~3个字节的偏移量。分支参数也可能代表指令范围的结尾。 例如，CBC_EXT_WITH_CREATE_CONTEXT 的 branch 参数显示 with 语句的结尾。 更确切地说，with子句中最后一条指令之后的位置 参数之间的组合限于以下7种情况： 无参数 只有一个字面量参数 只有一个字节参数 只有一个分支参数 一个字节参数和一个字面量参数 两个字面量参数 三个字面量参数 Literal（字面量）字面量被按照不同的类型组成字面量组，这与为每个字面量分配标志位相比更加节省空间。（以下提到的范围代表大于或等于范围左侧和小于右侧的那些标记。例如，字节码标头的ident_end和literal_end字段之间的范围包含这些标记， 大于或等于ident_end且小于literal_end。如果ident_end等于literal_end，则范围为空。） identifiers（标识符） 和 values（值） 是两个主要的字面量组： identifier：表示变量的名字。在 header 中字面量值介于0~ident_end之间。这种字面量必须为 string 或 undefined。undefined只能用来表示该字面量无法通过字面量名字访问到的情况。比如 function () {arg, arg}有两个参数，但这里的 arg 只能用来引用第二个参数。在这种情况下，第一个参数的名字就是 undefined。此外，诸如 CSE 之类的优化也可能引入不带名称的字面量。 value：表示立即值的引用。字面量值介于 ident_end 和 const_literal_end 之间的数字或字符串等。这种字面量可以直接被 VM 所使用。字面量值介于 const_literal_end 和 literal_end 的是模板字面量，比如函数和正则表达式。每次访问这类值都需要构造一个新对象。 identifiers 还有另外两个子组。寄存器是存储在函数调用堆栈中的那些标识符。 参数是由调用程序函数传递的那些寄存器。 在 CBC 中有两种类型的字面量编码，都是可变长度，1或2个字节。 small：最多可以编码511个字面量 单字节编码 0 - 254 之间的字面量 1byte[0] &#x3D; literal_index 双字节编码 255 - 510 之间的字面量 12byte[0] &#x3D; 0xffbyte[1] &#x3D; literal_index - 0xff full：最多可以编码 32767 个字面量 单字节编码 0 - 127 之间的字面量 1byte[0] &#x3D; literal_index 双字节编码 128 - 32767 之间的字面量 12byte[0] &#x3D; (literal_index &gt;&gt; 8) | 0x80byte[1] &#x3D; (literal_index &amp; 0xff) 因为大多数函数需要的字面量小于 255，所以 small 编码为所有字面量提供了一个单字节的字面量索引。与 full 编码相比，small 编码占用更少的空间但是范围有限。 Literal StoreJerryScript 没有用于字面量的全局字符串表，但是将它们存储在文字存储中。 在解析阶段，如果出现一个新的字面量，若其标识符与现有的标识符相同，则不会再次存储该字符串，但会使用字面量存储区中的标识符。 如果一个新的字面量不在Literal Store中，它将被插入。 Byte-code Categories（字节码类别）字节码可以被分为四个主要的类别： Push 字节码Call 字节码Arithmetic, Logical, Bitwise and Assignment 字节码（算数、逻辑、位、赋值）Branch 字节码Snapshot（快照）编译后的字节码可以保存到快照中，也可以加载回执行。 直接执行快照可以节省解析源的内存消耗和性能成本。 也可以直接从 ROM 执行快照，在这种情况下，还可以节省将快照加载到内存中的开销。 Virtual Machine（虚拟机）虚拟机是一个解释器，可逐一执行字节码指令。 解释的函数是位于 ./jerry-core/vm/vm.c 的 vm_run。 vm_loop是虚拟机的主循环，它具有非递归特性。 这意味着在函数调用的情况下，它不会递归地调用自身而是返回，这具有的好处是与递归实现相比不会加重堆栈。 ECMA引擎中 ECMA 组件负责以下四个功能： 数据表示 运行时 GC 数据表示数据表示的主要结构是 ECMA_value，这个结构中低三位编码了数据标签，用来确定数据类型： simple number string object symbol error 如果是数字，字符串和对象类型，则该值包含一个编码的指针，对于基础值是一个预定义的常量，可以是： undefined null true false empty (未初始化的值) 压缩指针为了节省堆空间，引入了压缩指针： 这些指针是 8 字节对齐的16位指针，可以寻址 512 Kb的内存，这也是 JerryScript堆的最大容量。 为了支持更多的内存，可以在构建时加上“ –cpointer_32_bit on”，将压缩指针的大小扩展到 32位，以覆盖 32位系统的整个地址空间。 “未压缩的指针”会将内存消耗增加大约20％。 数字根据 IEEE 754标准有两种可能的数字表示形式：默认值是8字节（双精度），但是引擎也支持将 JERRY_NUMBER_TYPE_FLOAT64设置为0来支持4字节（单精度）表示方式。 不支持多次引用单个分配的数字。每个引用都拥有自己的副本。 字符串JerryScript中的字符串不仅是字符序列，而且还可以包含数字和所谓的 magic ID。 对于常见的字符序列（在 ./jerry-core/lit/lit-magic-strings.ini 中定义），只读存储器中有一个表，其中包含 magic ID和字符序列对。 如果一个字符串已经在此表中了，则将存储其字符串的 magic ID 而非字符序列本身。 使用数字可加快属性访问以达到节省内存的目的。 Object / Lexical Environment（词汇环境）对象可以是常规数据对象或词法环境对象。 与其他数据类型不同，对象可以具有对其他数据类型的引用（称为属性）。 由于有循环引用，引用计数并不总是足以确定死对象。 因此，链列表是由所有现有对象组成的，可用于在垃圾回收期间查找未引用的对象。 每个对象的 gc-next 指针显示链表中的下一个分配对象。 Lexical environments 在 JerryScript 中实现为对象，因为其包含像对象一样的键值对（称为绑定）。 这简化了实现并减小了代码大小。 这些对象表现为如下结构： 引用计数器–硬（非属性）引用的数量 GC 的下一个对象指针 类型（函数对象或词汇环境等） 对象属性 对象有一个包含其属性的链表。此链表实际上包含属性对，为了节省内存：属性占7位，其类型字段占2位，共9位，这样一个字节就不够用需要占用两个字节，因此，将两个属性（14位）与2位的类型字段放在一起这样就能沾满2字节。 property hashmap（属性hash表）如果属性对的数量达到限制（当前此限制定义为16），则在属性对列表的第一个位置插入一个 Property Hashmap，以便使用它来查找属性，而不是通过在属性对上线性迭代来查询。 属性哈希表包含2^n个元素，其中 2^n 大于对象的属性数。 每个元素可以具有值的树类型： null，指代空元素 delete，指代被删除的元素，或者 对现有对象的引用 hashmap 是必须返回的类型的缓存，这意味着可以通过它找到对象所有的属性。 内部属性内部属性是一些特殊的属性，这些属性包含无法由 JavaScript 代码访问的元信息，但对引擎本身很重要。 内部属性的一些示例如下所示： [[Class]] – 对象的类（类型）（ECMA 定义） [[Code]] – 指向函数字节码的指针 native code（原生代码）– 指向原生函数代码的指针 Boolean [[PrimitiveValue]]（基础值）– 存储 Boolean 对象的 bool 值 Boolean [[PrimitiveValue]]（基础值）– 存储 Number 对象的数值 LCacheLCache是用于查找由对象和属性名称指定的属性的哈希表。 LCache 的对象-名称-属性布局在一行中连续显示多次，如下图： 访问属性时，将从所需的属性名称中提取hash值，然后使用该哈希值对 LCache 进行索引。 然后在索引行中搜索指定的对象和属性名称。 值得注意的是，如果在 LCache 中找不到指定的属性，这并不意味着它不存在（即LCache是可能返回的缓存）。 如果找不到该属性，则将在对象的属性列表中对其进行搜索，如果找到该属性则会将该属性放入LCache中。 CollectionsCollections 是类数组数据结构，优化用于节省内存。事实上，Collections是一个链表，其元素并非单个元素，而是一个包含多个元素的数组。 Exception Handling（异常处理）为了实现异常处理，JerryScript 的返回值能指示其错误或异常操作。其返回值是一个 ECMA 值，若发生错误操作则返回 ECMA_VALUE_ERROR 值。 Value Management and Ownership（值管理和所有权）引擎存储的每个 ECMA 值都与一个虚拟的 “所有权” 相关联，该所有权定义了如何管理该值：当不再需要它时何时释放它，以及如何将该值传递给其他功能。 最初，值是由其所有者（即用有所有权）分配的。 所有者有责任释放该值。 当将值作为参数传递给函数时，其所有权不会被传递，被调用函数必须制作一个自己的值副本。 但是，只要函数返回值，所有权就会传递，因此调用者将负责释放它。","permalink":"https://txiaozhe.github.io/2019/11/18/learning-jerryscript-design/","photos":[]},{"tags":[{"name":"Libuv","slug":"Libuv","permalink":"https://txiaozhe.github.io/tags/Libuv/"}],"title":"libuv 架构设计概述","date":"2019/10/18","text":"libuv 是一个原本为 Node.js 而编写，围绕着事件驱动的异步 I/O 模型而设计的跨平台库。 这个库为多个不同的I/O 循环机制提供了简单的抽象，如：‘handles’ 和 ‘streams’ 为 sockets 和其他实体提供高度抽象；除此之外也提供了跨平台文件 I/O 和线程功能。 libuv 架构如图： Handles(句柄) 和 requests(请求)libuv 结合事件循环为用户提供了两个协作对象的抽象：handles 和 requests。 Handles 表示活动时能执行某些操作的长期存活对象： prepare handle 在活动时每次循环迭代都会调用一次其回调。 TCP 服务器 handler 会在每次有新连接时调用其连接回调。 Requests 通常表示短期存在的操作。这些操作可以在一个handle上执行，例如：写请求在被用于在handle上写数据；或者独立的： getaddrinfo 请求不需要handle而直接在循环迭代中运行。 I/O 循环I/O (或事件) 循环是libuv 的核心部分。其构建了所有的 I/O 操作，并将其绑定到单个线程上。因此只要每个事件循环运行在不同的线程中，就可以同时运行多个事件循环。除非另有说明，libuv 事件循环（或任何涉及到事件循环或handle的 API）都不是线程安全的。 事件循环遵循常见的单线程异步 I/O 方式：在给定平台上，所有（网络）I/O 都使用最佳的机制在非阻塞的套接字中轮询执行：如 linux 的epoll；OSX或BSDs 的kqueue；SunOS 的event ports以及Windows的IOCP。作为循环迭代的一部分，循环将阻塞等待已添加到循环器中的套接字上的I/O 活动，并触发回调指示套接字条件（可读或可写的挂起）以便 handle 可以读取、写入或执行所需的 I/O 操作。 为了更好地理解事件循环的运作方式，下图说明了循环迭代的所有阶段： 更新 ‘now’。事件循环在开始处缓存当前时间以减少与时间相关的系统调用。 若循环是存活的则开始迭代，否则立即退出。那么什么情况下认为循环是存活的？当循环中存在活动的handle或被引用的 handle、活动中的请求或closing handles 时则认为循环是存活的。 执行到期的计时器。调用所有到期的计时器的回调。 调用上一轮循环推迟的回调。大多数情况下会在轮训 I/O 之后调用所有 I/O 回调。某些情况下这类回调会被推迟到下一个循环迭代。被推迟的 I/O 回调将在此时运行。 调用 idle handle。如果空闲handle是存活的，则会在每个循环中调用它们。 调用 prepare（就绪）handle。循环阻塞 I/O 前prepare handle回调将得到调用。 计算循环超时。在阻塞 I/O 前，循环会计算阻塞的时间，以下是计算超时的规则： 如果循环使用 UV_RUN_NOWAIT 标志运行，则超时为0； 如果循环即将停止（uv_stop() 被调用），则超时为0； 如果不存在任何存活的 handles 和 request，则超时为0； 如果有任何空闲的handle处于活动状态，则超时为0； 如果有任何要关闭的handle，则超时为0； 如果以上情况都不匹配，则采用最接近的定时器超时，或者当没有活动的定时器时，则为无穷大。 I/O 循环模块。此时，循环将在上一步计算的持续时间内阻塞 I/O，正在监视给定文件描述符的读写操作的所有与I / O相关的 handle 都将调用其回调。 调用 check handle。在 I/O 阻塞循环之后，check handle立即调用其回调，check handle 基本上对应着 prepare handles。 调用 close 回调。当通过调用 uv_close() 关闭 handle时将调用close 回调。 使用 UV_RUN_ONCE 标志运行的情况下的特殊阶段。阻塞 I/O 后可能没有触发任何 I/O 回调，但是此时已经过去了一段时间，因此可能会有到期的计时器，此时这些计时器回调将得到调用。 迭代末尾。如果循环是使用 UV_RUN_NOWAIT 或 UV_RUN_ONCE 模式运行的，则迭代将结束，并且uv_run() 将返回。如果循环是使用 UV_RUN_DEFAULT 运行的，那么如果循环仍然存活，则将从头开始继续，否则也将结束。 划重点：libuv 使用线程池使异步文件 I/O 操作成为可能，但是网络 I/O 始终在单个线程（每个循环的线程）中执行。 注意：尽管轮训机制不同，但libuv使执行模型在 Unix 系统和 Windows 之间保持一致。 文件 I/O与网络 I/O 不同，libuv 特定平台下没有可依赖的 I/O 操作原语，因此当前的实现方式是在线程池中运行阻塞的文件 I/O 操作。 有关跨平台文件 I/O 的详尽说明，查看此文章。 当前 libuv 使用全局线程池，所有循环都可以在该线程池上排队工作。当前在此线程池上运行3种类型的操作： 文件系统操作 DNS 函数（getaddrinfo 和 getnameinfo） 用户通过 uv_queue_work() 运行的特定代码 警告：有关更多详细信息，查看 “线程池工作调度” 部分，但是请记住，线程池的大小是非常有限的。","permalink":"https://txiaozhe.github.io/2019/10/18/libuv-design/","photos":[]},{"tags":[{"name":"Life","slug":"Life","permalink":"https://txiaozhe.github.io/tags/Life/"},{"name":"Job","slug":"Job","permalink":"https://txiaozhe.github.io/tags/Job/"}],"title":"多思无益","date":"2019/06/23","text":"今天约了一个朋友来家里吃饭，我烧了两斤的小龙虾，烹饪技术已经越来越娴熟。中间聊起行业和工作来，自诩有两年的从业经验，也能吹一点牛逼。他问我，python用处大吗？值得学习吗？我问他：你又不是做技术的，你学这个做什么用呢？他回答，据说用在数据处理上很方便很有用？！我心里当然是想打击一下他的，因为我觉得真的没用嘛！我是这样解释的，确实，现在行业内将python这门语言大量用在大数据处理，人工智能方面，确实很方便很实用，但这也仅仅是一门语言一个工具而已，除此之外恐怕也没有更多，也许我们可以更多地关注底下的东西。 我们常常说大数据，那什么样的数据算是大数据呢？是很多条数据吗？那多少条算多，一万条算多吗？一百万条算多吗？也许算吧！但我并不觉得这就是大数据。我总是希望将我的想法用简洁易懂的语言描述给不懂的人，于是我给他打了个比方。我说，在你眼里，大数据应该是一条河，一条滚滚向前奔流的河，而这条河的任意一段都无法展现这条河的真实面貌，你只能通过一些观察手段得到它某时某刻以某种方式展现在你面前的一个宏观体现。我想，这也是为什么大数据的结果往往接近现实的本质。 他可能没有听得很明白吧，不过我内心还是满足的，又在不懂行的人面前强行卖弄了一波。过去的半年多曾经在一家区块链公司任职，内心一度异常挣扎，挣扎的不是企业本身，而是自己有太多的看不懂。我常常思考价值的本质，或者说什么才是真正有价值的东西？是黄金？是纸币？亦或是那一串没有任何文本意义的比特币秘钥字符串？金融市场的价值来源在哪里？背后的价值支撑又在哪里？……历史起起伏伏又总是惊人相似，思考的结果，却只有两个字：信用？！ 在互联网行业内，我是一名程序员，不过我更喜欢被叫做工程师。我也总是自称开源（开放源代码）爱好者，不过代码贡献不算很多，也许只能算是一个伪开源爱好者吧。但我也常常思考开源的价值在哪里，也许我心里也是有一些答案的，也许是某种模式，也许是某种生态。我也是有一些开源理念和愿景的，跳出技术的思考模式，我常常觉得技术的价值并不在技术本身，而在于技术构建的产品和商业模式上，这种话语可能对于技术圈的人来说不是很中听吧！但事实出于思考与辩论。在我的理念里，技术是应该有它普世的价值的，这种价值看起来就在于是否降低了社会运作成本，是否打破某些壁垒，是否使众生平等…… 当然，过多的思考是无效的，当下先把技术搞懂~","permalink":"https://txiaozhe.github.io/2019/06/23/no-more-consider/","photos":[]},{"tags":[{"name":"Life","slug":"Life","permalink":"https://txiaozhe.github.io/tags/Life/"},{"name":"Job","slug":"Job","permalink":"https://txiaozhe.github.io/tags/Job/"}],"title":"记 Rokid 两周以及一次 ShadowNode MQTT 的 bug","date":"2019/06/20","text":"2019年6月某天，入职Rokid第2周，逐渐适应了新的办公环境和新的做事方式，开始接触IOT和端开发的概念，技术上慢慢地从服务端过渡到端开发，刚开始还是有些不适应，先讲一下个人感受吧！ 以前做过大规模的分布式系统，也做过小型的Web API，总结下来，做服务端开发要考虑更多的是Web接口、请求负载、网络性能以及如何更好地和客户端交互，大多数情况下不需要考虑太多机器的性能问题，因为一般情况下机器性能都是过剩和冗余的，对于企业来说，能花钱加机器解决的问题也一定不是问题，而且现在云服务盛行，大量的工具、平台都被打包成云服务出售，只要花上一点小钱钱就能获得很好的基础设施支撑，开发起来不要太爽，像把服务器性能榨干这种事情基本是被抛在脑后的。但端开发就是另外一种情景了，和服务端性能压力来自外部请求不同，端上的性能问题来自设备自身，当下呈现在端开发工程师面前的主要是嵌入式开发板、智能家居设备和可穿戴式设备等，CPU和内存资源少得可怜，同时也不可能像服务端那样通过增加设备来横向扩展，这就需要开发者去耐心地打磨底层的代码，想为所欲为地写代码秀操作？不存在的，碰到性能瓶颈？C语言伺候。 开始的这两周，主要以熟悉业务为主，开始还是有点吃力的，难点在于思维方式的转化，幸运的是大佬们都很耐心和细心，指导起来也不遗余力。熟悉业务以线上的各种bug为切入点，这两天就碰到一个关于MQTT协议的问题，经过两天的修复和审核，总算是将补丁打入主分支。 MQTT(消息队列遥测传输协议)，是一种基于发布/订阅模式的轻量级应用层通信协议，基于TCP协议构建，因为其低开销、低带宽占用的特点，使其在物联网(IOT)方面有着较广泛的应用。Rokid产品线基于YodaOS + ShadowNode 构建 IOT 应用，并使用 ShadowNode 内置的 MQTT 作为设备与移动端之间的通信协议。在某一时间点，用户爆出大量设备不在线的问题，初步分析是 MQTT 的问题，拿了一段 MQTT 订阅和发布的测试代码在本地运行，发现用 node 命令运行是没问题的，用 ShadowNode 运行就会出现断开连接的问题，确实是ShadowNode 本身的问题，再细致分析，发现客户端在 SUBSCRIBE 的时候会导致断开连接，于是深入MQTT源码，打印出 SUBSCRIBE 时发送的报文，再将其在 node 环境中运行打印正常的报文进行对比： 1282 2d 00 00 00 28 2f 64 65 76 69 63 65 2f 43 4d 43 43 2d 33 30 36 37 31 2d... # 错误报文82 2d 8d 05 00 28 2f 64 65 76 69 63 65 2f 43 4d 43 43 2d 33 30 36 37 31 2d... # 正确报文 对比正确的和错误的报文，发现第三和第四个字节是不一样的，看来是报文组装出问题了，为了验证这个猜想，我将正确的报文内容转成二进制通过ShadowNode发送，果然正确订阅，看来确实是协议的问题。鉴于本人也是第一次接触MQTT协议，没办法，只能去看MQTT协议文档了，本次修复查阅的是 3.1.1 版本的文档。 简单阐述一下MQTT协议，为了节省性能开支，其报文设计得相当紧凑环保。MQTT的报文分为固定报头、可变报头和有效载荷三部分，固定报头是必须存在的，用于描述报文类型、等级等信息，可变报头不一定存在，这取决于报文的类型，有效载荷存放的是通信内容。如上所示，前两个字节是固定报头，第一个字节（82）前四位表示类型，这里8表示SUBSCRIBE消息，后四位表示指定控制报文类型的标志位，目前只用到0010，也就是2。第二个字节表示消息的剩余长度，也就是可变报头+负载的长度总和。第三第四个字节为可变报头部分，包含一个用于确认消息传递状态的报文标识符（PacketId），该标识符由报文类型决定存在与否，当发布PUBLISH消息且QoS &gt; 0时是必须存在的，且发送 SUBCRIBE 消息时也是必须存在的，问题就出在这里，在 ShadowNode 的 MQTT 协议实现中会传入一个从0开始递增的PacketId，首次 SUBCRIBE 时该 PacketId 为0，这就导致底层处理时认为该位为空而不写入该段报文，也就是为什么上面看到的错误报文的第三和第四字节为00 00，正常情况下应该写入一个两字节的非零数字作为PacketId。至于开始时为什么不出错，也许是应用该MQTT实现的一端开始时并没有真正将这个PacketId 用来校验消息状态，而后期迭代的时候开发人员良心发现突然又校验了，从而导致报文错误。Bug 原因已找出，是时候修复一下了，由于 ShadowNode 中 MQTT 的实现还没有很完善，后期还需要做更多的适配，而业务线又出现 Bug 需要紧急修复，因此目前只做了应急措施，将上述 PacketId 的递增初始值设置为1，进而解决了该问题，真是一个数字导致的血案~ 为了适应协议文档中对QoS的处理，本次补丁还对 QoS 进行了初步的校验，补丁地址，这是情急之下做的紧急修复，如有问题欢迎在 ISSUE 中提出 :) 两周下来，切实感受到 Rokid 确实是一片丛林，挣扎并有趣~ 可期！","permalink":"https://txiaozhe.github.io/2019/06/20/mqtt-hotfix/","photos":[]},{"tags":[{"name":"CockroachDB","slug":"CockroachDB","permalink":"https://txiaozhe.github.io/tags/CockroachDB/"},{"name":"SQL","slug":"SQL","permalink":"https://txiaozhe.github.io/tags/SQL/"}],"title":"添加一个新的SQL语句","date":"2019/04/24","text":"前言CockroachDB是著名的开源NewSQL数据库，对外提供了标准的SQL接口。上一篇文章《CockroachDB的Parser模块实现》介绍了CockroachDB中Parser模块，主要通过词法解析器将SQL语句解析成Token，然后通过语法解析器生成抽象语法树。本文将介绍如何在CockroachDB中添加一个新的SQL语法类型，来实现用户自定义的功能，并添加相应的测试，从而加深对相应模块的代码及原理的理解。 添加一个新的SQL语句添加一个新的SQL语句，首先需要在SQL parser中添加必要的语法规则。CockroachDB的parser是通过 goyacc （go语言构建的一个yacc编译器）解析语法规则文件（pkg/sql/parser/sql.y）生成的。parser生成一颗抽象语法树（AST*），其树节点的定义在代码目录 *pkg/sql/sem/tree 下。 在parser中添加一个新的SQL语句有三个关键部分： 添加新的关键字； 添加语法解析规则； 添加新的语法节点类型 我们将尝试在CockroachDB v2.1中添加一个新的SQL语句：FROBNICATE ，这个SQL语句支持三种语法，功能如下： FROBNICATE CLUSTER ：在服务端打印 “It’s FrobnicateModeCluster” FROBNICATE SESSION：在服务端打印 “It’s FrobnicateModeSession” FROBNICATE ALL：在服务端打印 “It’s FrobnicateModeALL” 添加新的关键字第一步需要先定义关键字。在pkg/sql/parser/sql.y 文件中搜索”%token”，可以看到声明了许多token，例如我们语法中需要用到的SESSION、CLUSTER、ALL*都已经存在了，因此我们只需要添加关键字 *FROBNICATE 即可，如下所示： 1%token &lt;str&gt; FROBNICATE 如果关键字可以出现在标识符选项中，则必须保留该关键字（在需要使用它的地方，例如在列名中，必须使用双引号引起来），因此我们还需要将该关键字添加到”unreserved keywords”列表中，避免与标识符混淆。 1234unreserved_keyword:....| FROBNICATE... 至此词法分析器已经能识别我们所有的关键字了，接下来需要告诉语法解析器如何处理新的语句。 添加语法解析规则添加语法解析规则涉及到下列三个部分： 类型列表 语法case列表 子句解析规则 在 sql.y 文件中搜索”tree.Statement”，可以看到定义好的类型列表，在这里添加一个新的语法类型，如下所示： 1%type &lt;tree.Statement&gt; frobnicate_stmt 然后搜索 “stmt: “，为新的语句类型添加一个case： 1234stmt:...| frobnicate_stmt &#x2F;&#x2F; EXTEND WITH HELP: FROBNICATE... 最后，我们需要在stmt中为新的语句添加语法规则及相应的帮助信息，如下所示： 1234567&#x2F;&#x2F; %Help: FROBNICATE - show the simple message&#x2F;&#x2F; %Category: Misc&#x2F;&#x2F; %Text: FROBNICATE &#123; CLUSTER | SESSION | ALL &#125;frobnicate_stmt:FROBNICATE CLUSTER &#123; return unimplemented(sqllex, &quot;frobnicate cluster&quot;) &#125;| FROBNICATE SESSION &#123; return unimplemented(sqllex, &quot;frobnicate session&quot;) &#125;| FROBNICATE ALL &#123; return unimplemented(sqllex, &quot;frobnicate all&quot;) &#125; 至此，parser已经能够识别新的语法类型并提示相应信息了。此处我们暂时使用unimplemented来代替该语法具体的操作，后续我们会继续完善该部分内容。 我们来尝试使用新的语法，首先需要产生 sql.go 文件： 12345~/go/src/github.com/cockroachdb/cockroach$ make generate...Type checking sql.yCompiling sql.go... 然后重新编译： 123~/go/src/github.com/cockroachdb/cockroach$ make build...github.com/cockroachdb/cockroach 使用新编译的二进制文件，起一个CockroachDB单节点实例： 1234$ rm -fr cockroach-data/ &amp;&amp; ./cockroach start --insecure...status: initialized new cluster... 另起一个终端，运行刚才添加的新语句： 这里虽然出现了umimplemented 报错，提示该语句还未完成，不过这时已经可以解析该语法了。如果执行一个不存在的语句，提示的错误则是 syntax error： 添加新的语法节点类型现在我们已经可以解析相关语法，接下来还需要为该语句添加适当的语义。我们需要一个AST（抽象语法树）节点来将语句的结构信息从parser传递到runtime。 上文中我们在sql.y中添加过%type &lt;tree.Statement&gt;，因此我们还需要实现tree.Statement接口，该接口的定义在pkg/sql/sem/tree/stmt.go中，它有4个方法需要实现： fmt.Stringer NodeFormatter StatementType() StatementTag() 首先创建一个新文件pkg/sql/sem/tree/frobnicate.go，在该文件中实现相关AST节点： 1234567891011121314151617181920212223242526272829303132333435package parserimport \"bytes\"type Frobnicate struct &#123; Mode FrobnicateMode&#125;var _ Statement = &amp;Frobnicate&#123;&#125;type FrobnicateMode intconst ( FrobnicateModeAll FrobnicateMode = iota FrobnicateModeCluster FrobnicateModeSession)func (node *Frobnicate) StatementType() StatementType &#123; return Ack &#125;func (node *Frobnicate) StatementTag() string &#123; return \"FROBNICATE\" &#125;func (node *Frobnicate) Format(buf *bytes.Buffer, f FmtFlags) &#123; buf.WriteString(\"FROBNICATE \") switch node.Mode &#123; case FrobnicateModeAll: buf.WriteString(\"ALL\") case FrobnicateModeCluster: buf.WriteString(\"CLUSTER\") case FrobnicateModeSession: buf.WriteString(\"SESSION\") default: panic(fmt.Errorf(\"Unknown FROBNICATE mode %v!\", node.Mode)) &#125;&#125;func (node *Frobnicate) String() string &#123; return AsString(node)&#125; 接下来我们需要更新parser，让它在遇到该语句时返回相应的Frobnicate节点。 上文在 sql.y 文件中添加frobnicate_stmt规则时，使用了unimplemented来暂时代替具体实现，现在我们来实现这部分内容： 1234567&#x2F;&#x2F; %Help: FROBNICATE - twiddle the various settings&#x2F;&#x2F; %Category: Misc&#x2F;&#x2F; %Text: FROBNICATE &#123; CLUSTER | SESSION | ALL &#125;frobnicate_stmt:FROBNICATE CLUSTER &#123; $$.val &#x3D; &amp;tree.Frobnicate&#123;Mode: tree.FrobnicateModeCluster&#125; &#125;| FROBNICATE SESSION &#123; $$.val &#x3D; &amp;tree.Frobnicate&#123;Mode: tree.FrobnicateModeSession&#125; &#125;| FROBNICATE ALL &#123; $$.val &#x3D; &amp;tree.Frobnicate&#123;Mode: tree.FrobnicateModeAll&#125; &#125; 重新编译，然后通过客户端运行该语句： 这里返回了一个错误，不过这是一个来自SQL planner的错误，当SQL planner识别到新的语法节点但是不知道该如何处理时就会报这个错误。 我们需要告诉planner如何处理这个语法，相应的代码在 pkg/sql/plan.go 中，我们在newPlan函数中为其添加一个case： 123switch n := stmt.(type) &#123;case *tree.Frobnicate: return p.Frobnicate(ctx, n) 然后我们在 pkg/sql/frobnicate.go 中实现对应的方法： 12345678910package sqlimport ( \"context\" \"fmt\" \"github.com/cockroachdb/cockroach/pkg/sql/sem/tree\")func (p *planner) Frobnicate(ctx context.Context, stmt *tree.Frobnicate) (planNode, error) &#123; return nil, fmt.Errorf(\"We're not quite frobnicating yet...\")&#125; 再次编译并运行： 这里已经根据相应函数内的代码返回了一个错误，接下来我们修改该函数，实现打印出对应信息的功能： 12345678910111213func (p *planner) Frobnicate(ctx context.Context, stmt *tree.Frobnicate) (planNode, error) &#123; switch stmt.Mode &#123; case tree.FrobnicateModeCluster: fmt.Println(\"It's FrobnicateModeCluster\") case tree.FrobnicateModeSession: fmt.Println(\"It's FrobnicateModeSession\") case tree.FrobnicateModeAll: fmt.Println(\"It's FrobnicateModeAll\") default: return nil, fmt.Errorf(\"Unhandled FROBNICATE mode %v!\", stmt.Mode) &#125; return &amp;zeroNode&#123;&#125;, nil&#125; 注意：这里直接返回zeroNode，它是一个不包含任何行和列的planNode，所以客户端将看不到任何数据返回。如果你需要返回一些内容给客户端，可以查看 pkg/sql 包下是否有合适的planNode，或者使用自定义的planNode。 重新编译并运行： 123./cockroach sql --insecure -e \"frobnicate cluster\"./cockroach sql --insecure -e \"frobnicate session\"./cockroach sql --insecure -e \"frobnicate all\" 这时在服务端屏幕可以观察到已经打印出对应的内容： 至此我们已经实现了一个简单的 frobnicate 语法，别忘了最后还有一个重要步骤，添加相应的测试用例。 添加测试用例此处需要为该语法解析添加测试用例，相关测试代码位于 pkg/sql/parser/parse_test.go ，我们只需要在对应的地方加入需要测试的语法即可： 123&#123;&#96;FROBNICATE CLUSTER&#96;&#125;,&#123;&#96;FROBNICATE SESSION&#96;&#125;,&#123;&#96;FROBNICATE ALL&#96;&#125;, 然后运行测试: 1$ make test 如果在上述过程中可以顺利添加语句并成功编译构建，则此处应当可以成功跑通相应的测试用例。 关于SQL语句的功能测试代码在 pkg/sql/logictest/ 下相应文件中，只需要在对应的地方添加新的SQL语句和期望的返回结果即可。由于此处我们仅实现了服务端打印的测试功能，便不具体在此处进行测试，感兴趣的同学可以自行查看对应的测试文件。 给SQL语句添加别名如果我们需要经常运行Frobnicate语句，希望它可以更简洁的话，我们也可以给它添加一个别名FROB，实现过程很简单，只需要在sql.y中添加几行规则即可： 123456789101112unreserved_keyword:...+ | FROB| FROBNICATE...frobnicate_stmt:FROBNICATE CLUSTER &#123; $$.val &#x3D; &amp;tree.Frobnicate&#123;Mode: tree.FrobnicateModeCluster&#125; &#125;| FROBNICATE SESSION &#123; $$.val &#x3D; &amp;tree.Frobnicate&#123;Mode: tree.FrobnicateModeSession&#125; &#125;| FROBNICATE ALL &#123; $$.val &#x3D; &amp;tree.Frobnicate&#123;Mode: tree.FrobnicateModeAll&#125; &#125;+ | FROB CLUSTER &#123; $$.val &#x3D; &amp;tree.Frobnicate&#123;Mode: tree.FrobnicateModeCluster&#125; &#125;+ | FROB SESSION &#123; $$.val &#x3D; &amp;tree.Frobnicate&#123;Mode: tree.FrobnicateModeSession&#125; &#125;+ | FROB ALL &#123; $$.val &#x3D; &amp;tree.Frobnicate&#123;Mode: tree.FrobnicateModeAll&#125; &#125; 总结本文通过一个添加SQL语句的案例，介绍了SQL语句在CockroachDB代码中的实际解析和处理流程。本文所使用的案例参考了https://github.com/cockroachdb/cockroach/blob/master/docs/codelabs/01-sql-statement.md 中的案例，为了便于读者理解，在实现具体功能时直接在服务端打印内容并返回zeroNode。关于planner和生成执行计划相关的原理及实现，会在后续的SQL引擎系列文章中进行详细介绍。","permalink":"https://txiaozhe.github.io/2019/04/24/add-a-new-sql/","photos":[]},{"tags":[{"name":"Life","slug":"Life","permalink":"https://txiaozhe.github.io/tags/Life/"},{"name":"Job","slug":"Job","permalink":"https://txiaozhe.github.io/tags/Job/"}],"title":"给2019起个好头","date":"2019/01/28","text":"或许是受到某大佬的感染，也有可能是因为最近工作方面的变故比较多，想写点东西，想想几年前我也曾是个喜欢写写文章，小诗，偶尔还学着刻印章的文艺二逼青年~ 我是不玩知乎的，但偶尔有好的文章也会打开来看。这是我在知乎的第一篇文章，希望也能开一个好头。简单介绍我自己吧！本人94年11月生人，妥妥的90后，算是有幸摸到了一点点95后的脑袋。13年上大学，17年毕业，程序猿，毕业前后在一家小创业公司就职，但无奈面临的问题太多太复杂，已经无法妥善解决，公司状况也超出了我的最坏预期，个人财务状况几近破产，于是多方思考后于2017年10月来到杭州（也因为我是浙江人），并就职于全民TV，后由于全民破产不得不出走（还被拖欠工资，想想就气人，手动讨伐），目前就职于一家区块链公司，日常打杂。其实我并非计算机专业出身，本科专业是高分子材料与工程，可以说是跟计算机没有半毛钱关系，至于说为什么会走上这条路，这个过程异常曲折，也曾经被质疑，那些已经足以写一篇文章了，我想说，有困难，有缘分，有机遇，也有努力。 一直以来，我是一个对游戏，玩这些事情无感的人，不过我仍然会去旅行，但不会奔着风景去，我会更加看重我去那个地方能见到什么人，能得到什么收获。大学四年以及毕业一年半以来，去的地方不多，北京、上海、深圳、苏州、南昌…，每当去那些大城市，总会带着一些事情或者要见某个人的目的而去，见完之后急匆匆赶上返程的火车，家里人也常常埋怨我，既然去了，何不多玩几天？我也总是敷衍：下次吧，以后有的是机会！在我眼里北京是一个没有印象中那么发达的地方，北京人不友好，还有，雾霾真的非常严重！上海依然繁华，而苏州也是一个美丽而又富有韵味的城市，还是蛮讨人喜欢的，深圳，节奏很快吧，至于南昌，emmmm…，但总体对比下来，我仍然最喜欢我的杭州，我想杭州是有一些东西在吸引着我的，西湖，湿地，四季…… 在杭州也已有一年多了，工作上面没有当初想的那么的一帆风顺，在第一份正式工作上就经历了破产倒闭，大小目标一再搁浅，也没有像当初想的那样找到女朋友，但我至始至终都给自己一个信念，不管在哪里，不论最终结局如何，都要心存感激，我也始终感恩全民TV给我带来的知识与成长，也相信未来会变好。 我想我仍然是一个很有心的人，和很多年前一样，那时候的我，会以献血来纪念成年，会凌晨三点一个人跑上山去看日出，会因为喜欢一个人做很多傻事。而现在的我会在周末邀请朋友们来家里吃饭，小小的出租屋，我也会做一桌好菜，是的，我喜欢做菜，相比吃，我更享受那个过程。饭桌上谈笑风生，很无聊，也很有趣。桌上常备一束花，有时是百合，秋天可以摆桂花，简单点就绿萝，快入春了，栀子花会很香。一个人的生活，简单而又丰富。最近看了一篇文章，北大研究生放弃白领工作从事外卖员，起初感觉又是这种噱头式的狗血故事，但我硬是耐着性子看完了那篇两万多字的文章，后来发现人家确实比我强多了，至少他在这个过程中思考出了一些结论，而我呢？我也曾经多次把自己投放到社会底层的工作中去，初中毕业走上社会，做过服务员，发过传单，甚至在工地上做过苦力，然而对于这些经历，好像我的收获只有在别人面前吹嘘自己的经历如何丰富，走在钱塘江边上的时候指着那幢大楼说自己曾经是它的建设者。而这一切，对于现在的我，却显得没有任何意义。在那些做苦力的日子里，我学着他们抽烟，讲脏话，打架斗殴，骑着车在路上狂飙的时候，感觉自己没有那么渺小，整个世界都是我的。在那些有些黑暗的地方，我曾经看到过一些不一样的社会与现实，甚至有过一种融入进去混沌一生的错觉，但终究还是走了出来，我也一直庆幸，我想，我跟他们是不一样的。 我常常思考很无聊的问题，比如如何去做事！我的工作经历也许相当“丰富”了，但我依然没有想明白，我的解决办法是不要想，先去做。就像在大学的时候，自学计算机，怎样描述那时候的困难与努力呢？我印象最深的是，一个懵懂的学弟问我怎样学计算机，我跟他说，图书馆，二楼，理科阅览室，靠近窗户那一排书架，中间一层摆满了计算机的书，都是我放在那里的，感兴趣可以去翻一下！那时候的点点滴滴，已经化解为一个又一个的坐标，中间也受到很多的质疑，但我总是坚定。到现在，工作之余，我会关注社区，开始无偿为一些开源项目贡献，也因此结识了很多的小伙伴。现在，我开始有了一个信念：把事情做到位了，会有意外的收获。我一直在寻找一些真正有价值的东西，我发现，我的坚持开始变得有价值。 入冬以来，也许很多人的感受是一样的，冷。确实，大环境的变故总是那么猝不及防，而我们作为其中的个体又显得那么无力，我自己的规划也在一次次重组、裁员的消息中无所适从。昨天见了一个朋友，闲聊之中，我跟他说，最近很颓，不知所措。尽管如此，我也还是获取到正能量的，无论如何，相信一切都会变好~ 大学毕业一路以来的思考与感受，可笑勿喷 :)","permalink":"https://txiaozhe.github.io/2019/01/28/2019-begin/","photos":[]},{"tags":[{"name":"ShadowNode","slug":"ShadowNode","permalink":"https://txiaozhe.github.io/tags/ShadowNode/"},{"name":"Nodejs","slug":"Nodejs","permalink":"https://txiaozhe.github.io/tags/Nodejs/"}],"title":"ShadowNode 源码解析之 module","date":"2018/12/20","text":"ShadowNode 是一款可以运行于嵌入式设备的js运行时，基于Samsung的iotjs项目开发，和node相比，其具有更小的内存占用和更快的启动速度，不过作为contributor之一，给我很直观的感受就是ShadowNode具有极快的编译速度，开发起来也更加顺畅。我从2018年10月开始利用业余时间参与ShadowNode的开发和维护，为其提交了数个补丁和特性，因此也逐渐对其有了一定的了解，在此我将对ShadowNode从源码的角度对其进行解析以及我个人对ShadowNode的一些疑惑和思考。因为大部分实现与node一致，而且团队也一直希望将ShadowNode做到与node兼容，因此此解析也适用于理解node源码。在此也希望ShadowNode能越来越普及，并为node社区开拓一片新的领域。 本文主要讲述ShadowNode中module模块的实现。module是node中最重要的模块之一，在ShadowNode中也是如此。和node一样，ShadowNode也支持CommonJS的模块形式，实现方式略有不同，但使用方式与node基本一致。 module模块在node和ShadowNode中的重要性不言而喻，从启动时便要用于加载脚本。废话不多说，接下来先解析一波源码，我们从入口文件ShadowNode/src/js/iotjs.js（为什么还要叫iotjs呢？其实我一直想向团队建议改个名字，比如snode啥的@yorkie:) ）开始，这里面包含了一个IIFE的函数，ShadowNode/src/js/iotjs.js line: 23 12345678910111213141516171819202122function Module(id) &#123; this.id = id; this.exports = &#123;&#125;;&#125;Module.cache = &#123;&#125;;Module.require = function(id) &#123; if (id === 'native') &#123; return Module; &#125; if (Module.cache[id]) &#123; return Module.cache[id].exports; &#125; var module = new Module(id); Module.cache[id] = module; module.compile(); return module.exports;&#125;; 可以看到这里定义了一个Module类，但这还不是我们日常使用的那个module模块，这里进行了if (id === &#39;native&#39;)的判断，后面会用到，然后从缓存中获取模块，我们可以看到不管是node还是ShadowNode，缓存的概念都是一以贯之的，这极大地提升了模块加载的性能，最后将模块返回。而后移到ShadowNode/src/js/iotjs.js line: 51 1var module = Module.require('module'); 这里调用了上述Module类的require静态方法来加载真正的module模块所在地：ShadowNode/src/js/module.js，并运行compile成员方法，里面会调用process.compileModule()方法，这是用c代码实现的内置process模块，在此我不详细讲述process的内容，之后会用专门的篇幅进行解析。compileModule() 用于将模块载入内存，成为运行时的一部分，也就可以用于运行与调用了。简单来说，这入口文件主要执行了诸如：ShadowNode/src/js/iotjs.js line: 384 123global.console = Module.require('console');global.Buffer = Module.require('buffer');global.Promise = Module.require('promise'); 以及：ShadowNode/src/js/iotjs.js line: 496 12process.exit = function(code) &#123; ... 等我们熟悉的全局模块、方法以及常量的定义与加载操作，为系统启动做足准备工作，但这不是我们现在所关心的，因此移步至 ShadowNode/src/js/iotjs.js line: 603 12var m = Module.require('module');m.runMain(); 这里再次加载了一个上述真正的module模块实现文件并执行了其静态的runMain方法，因此我们移步至ShadowNode/src/js/module.js：line: 335 12345678910iotjs_module_t.runMain = function() &#123; if (process.debuggerWaitSource) &#123; var fn = process.debuggerSourceCompile(); fn.call(); &#125; else &#123; var filename = mainModule.filename = process.argv[1]; mainModule.exports = iotjs_module_t.load(filename, null); &#125; while (process._onNextTick());&#125;; 我们现在着重关注以下代码： 12var filename = mainModule.filename = process.argv[1];mainModule.exports = iotjs_module_t.load(filename, null); 这里将process.argv[1]所指代的变量作为文件名，也就是当执行$ iotjs xxx.js时需要加载的文件，也就是说这里会加载用户指定的文件进行解析并运行，紧接着调用iotjs_module_t.load(filename, null);来执行加载操作，看一下load方法的实现： ShadowNode/src/js/module.js：line: 220 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950iotjs_module_t.load = function(id, parent) &#123; if (process.builtin_modules[id]) &#123; iotjs_module_t.curr = id; return Native.require(id); &#125; var module = new iotjs_module_t(id, parent); var modPath = iotjs_module_t.resolveModPath(module.id, module.parent); var cachedModule = iotjs_module_t.cache[modPath]; if (cachedModule) &#123; iotjs_module_t.curr = modPath; return cachedModule.exports; &#125; if (!modPath) &#123; throw new Error('Module not found: ' + id); &#125; var stat = process._loadstat(); var startedAt; if (stat) &#123; startedAt = Date.now(); &#125; module.filename = modPath; module.dirs = [modPath.substring(0, modPath.lastIndexOf('/') + 1)]; iotjs_module_t.cache[modPath] = module; iotjs_module_t.curr = modPath; var ext = modPath.substr(modPath.lastIndexOf('.') + 1); if (ext === 'jsc') &#123; module.compile(true); &#125; else if (ext === 'json') &#123; var source = process.readSource(modPath); module.exports = JSON.parse(source); &#125; else if (ext === 'node') &#123; var native = process.openNativeModule(module.filename); module.exports = native; &#125; else &#123; /** Treat any other file as js file */ module.compile(); &#125; if (stat) &#123; var relPath = modPath.replace(cwd, ''); var consume = Math.floor(Date.now() - startedAt); console.log(`load \"$&#123;relPath&#125;\" $&#123;consume&#125;ms`); &#125; return module.exports;&#125;; 这个方法也是全局require方法所执行的模块加载操作，其中的加载流程和node相同，首先查询是否是内置模块，如果是，则直接返回内置模块，如果不是，则解析模块名，并对缓存进行查询，这里使用绝对路径作为缓存存储的键以避免重复缓存，如果缓存中存在，则直接返回，否则解析模块文件并加载，这里会识别jsc、json、node的文件以使用对应方式进行解析，否则，其他文件都将作为js文件进行解析。最终将module.exports返回。至此，模块就被加载了。 那么问题来了，全局的require函数是怎么就能直接使用了呢？这也是我刚开始看源代码时心中所带的问题。到现在好像也没有看到有相关的操作，那接下就可以分析一下上述代码的compile方法了！以下是compile成员方法的实现：ShadowNode/src/js/module.js：line: 272 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152function _makeRequireFunction(mod) &#123; var Module = mod.constructor; function require(id) &#123; return mod.require(id); &#125; function _resolve(request) &#123; if (!request || typeof request !== 'string') &#123; throw new TypeError('module must be a non-null string'); &#125; if (process.builtin_modules[request]) &#123; return request; &#125; var path = Module.resolveModPath(request, mod); if (!path) &#123; throw new Error('Module not found: ' + request); &#125; return path; &#125; require.resolve = _resolve; require.main = mainModule; require.cache = Module.cache; return require;&#125;iotjs_module_t.prototype.compile = function(snapshot) &#123; var __filename = this.filename; var __dirname = path.dirname(__filename); var fn; if (!snapshot) &#123; fn = process.compile(__filename); &#125; else &#123; fn = process.compileSnapshot(__filename); if (typeof fn !== 'function') throw new TypeError('Invalid snapshot file.'); &#125; var _require = _makeRequireFunction(this); fn.apply(this.exports, [ this.exports, // exports _require, // require this, // module undefined, // native __filename, // __filename __dirname // __dirname ]);&#125;; 这里并没有很复杂的实现，通过process.compile(__filename)和process.compileSnapshot(__filename)创建运行的事例，并组装好require等参数，通过fn.apply(...)将exports、require、module、__filename等我们熟悉的全局函数和对象传入，至此，我们最熟悉的那些模块函数也就可以用了。不过到此为止，好像还缺了点什么，对，还没说ShadowNode模块是怎么寻址的呢！这里我们从iotjs_module_t.resolveModPath(...)方法开始，这个方法在iotjs_module_t.load(...)和require.resolve(...)方法中用于模块寻址： ShadowNode/src/js/module.js：line: 166 123456789101112131415161718192021222324iotjs_module_t.resolveModPath = function(id, parent) &#123; if (parent != null &amp;&amp; id === parent.id) &#123; return false; &#125; var filepath = false; if (id[0] === '/') &#123; filepath = iotjs_module_t._resolveFilepath(id, false); &#125; else if (parent === null) &#123; filepath = iotjs_module_t._resolveFilepath(id, cwd); &#125; else if (id[0] === '.') &#123; var root = path.dirname(parent.filename); filepath = iotjs_module_t._resolveFilepath(id, root); &#125; else &#123; var dirs = iotjs_module_t.resolveDirectories(id, parent); filepath = iotjs_module_t.resolveFilepath(id, dirs); &#125; if (filepath &amp;&amp; (filepath.indexOf('./') &gt; 0 || filepath.indexOf('../') &gt; 0)) &#123; return iotjs_module_t.normalizePath(filepath); &#125; return filepath;&#125;; parent是指调用目标模块的模块，也属于module的实例，而后根据模块路径的形式和传入的parent值指定模块寻址的起点，比如当parent === null时传入cwd作为寻址起点，也就是脚本运行的当前目录。接下来是iotjs_module_t._resolveFilepath(...)：ShadowNode/src/js/module.js：line: 129 1234567891011121314151617181920212223242526272829303132333435iotjs_module_t._resolveFilepath = function(id, root, ext_index) &#123; var modulePath = root ? path.join(root, id) : id; var filepath; var exts = ['.js', '.json', '.node']; if (ext_index === undefined) &#123; ext_index = 0; &#125; // id[.ext] if (filepath = tryPath(modulePath, exts[ext_index])) &#123; return filepath; &#125; // id/index[.ext] if (filepath = tryPath(modulePath + '/index', exts[ext_index])) &#123; return filepath; &#125; // 3. package path id/ var jsonpath = modulePath + '/package.json'; filepath = iotjs_module_t.tryPath(jsonpath); if (filepath) &#123; var pkgSrc = process.readSource(jsonpath); var pkgMainFile = JSON.parse(pkgSrc).main; // pkgmain[.ext] if (filepath = tryPath(modulePath + '/' + pkgMainFile, exts[ext_index])) &#123; return filepath; &#125; &#125; ext_index++; if (ext_index &lt; exts.length) &#123; return iotjs_module_t._resolveFilepath(id, root, ext_index); &#125;&#125;; 此函数将目标模块的路径进行组合并尝试读取模块文件，在这里会识别js、json、node 三种格式的文件以及index.*默认文件，若读取失败，则尝试读取package.json中依赖的模块，最终返回完整的模块路径。后续对模块地址进行整理即返回，模块的寻址也就结束了。 以上内容描述了ShadowNode中module模块的实现过程，包括全局对象的构建、模块寻址、缓存优化等，但其中有一些细节比如process.compile(...)如何对模块文件进行编译以及snapshot构建等问题没有深入论述，后续随着我参与项目构建的深入我还会继续详解。 作为一个开源爱好者，也是一名noder，我对ShadowNode的关注由来已久，但真正参与构建也就近两个月的事情，一直以来我对这个项目保留了一些疑问和不解，对此我也特地和ShadowNode作者@yorkie有过一次详谈，一方面从性能角度来看，js并不优良的性能以及它的运行环境对系统资源的巨大消耗决定了其绝对不是构建嵌入式设备应用的绝佳选择，开源社区对类似运行时的diss也基本集中在这方面；另一方面从生态的角度来看，虽然js的生态非常完备，尤其是在node和npm崛起之后，但嵌入式设备应用开发本身也并不是一个巨大的需求，因此对于构建这样一个类node且运行于嵌入式设备的运行时是否具有现实意义，我一直是存疑的。对此，yorkie也给了解答，构建ShadowNode的动机很简单，其实就是看中js本身所具有的巨大生态支撑，而其他并没有太多考虑（事实上也不值得考虑太多），yorkie还用了Android的例子，选择Java作为其开发语言并不是看中Java的性能，而是其强大的生态。确实，这没毛病，而且最终Android也反过去助长了Java生态的增长。尽管这一点也并没有绝对说服我，但ShadowNode的最终目标在于社区建设和生态构建，且对未来发展有更多的憧憬与期待而非该技术本身这一点，也还是令我信服的。 以上是我对ShadowNode实现的简单阐述及我个人粗浅的看法与理解，有错误或遗漏的部分欢迎指正 : ) 2018-12-20","permalink":"https://txiaozhe.github.io/2018/12/20/snode-module/","photos":[]},{"tags":[{"name":"Life","slug":"Life","permalink":"https://txiaozhe.github.io/tags/Life/"},{"name":"Job","slug":"Job","permalink":"https://txiaozhe.github.io/tags/Job/"}],"title":"在西溪湿地做景区管理员","date":"2018/12/18","text":"西溪湿地风光","permalink":"https://txiaozhe.github.io/2018/12/18/xixi/","photos":[]},{"tags":[{"name":"Job","slug":"Job","permalink":"https://txiaozhe.github.io/tags/Job/"},{"name":"Mac","slug":"Mac","permalink":"https://txiaozhe.github.io/tags/Mac/"},{"name":"Tech","slug":"Tech","permalink":"https://txiaozhe.github.io/tags/Tech/"}],"title":"更改Bash版本引发的Mac事故","date":"2018/08/22","text":"之前参与了CockroachDB的文档翻译，总觉得不够，希望能参与到项目的开发中。于是查看各种文档，开发指南。幸好CockroachDB 官方有完整的开发指导，于是我就按照开发指引来进行环境的搭建，使用的电脑是2017款MacBook Pro，OSX 10.13.3，8Gb，Core i5。 项目开发对环境有很多要求，比如C++需要支持11版本，Go版本需要1.9+等等，其中还有一条要求，Bash的版本需要在 4+，我们都知道，mac默认的bash是3.2版本的，因此需要进行升级。升级的方法是网上查的，使用brew 进行安装： 1$ brew install bash 但是可执行文件会被安装到 /usr/local/Cellar/bash 中，而真正的 bash 仍在 /bin/bash 中，为了方便会用4+版本的bash，需要对命令指向进行改动。 按照教程，因为Mac系统引入了sip机制禁止更改系统目录的权限，因此需要先关闭sip机制再进行修改： 重启OSX，启动时快速按住 cmd + R 出现系统恢复界面后，标题栏选择 Utilities - menu ，进入Terminal 输入 csrutil disable 关闭SIP( csrutil enable 为打开SIP) 重启Mac 此时Mac正常启动，进入正常使用的界面，输入以下命令修改 bash 指向： 12$ sudo mv /bin/bash /bin/bash.origin$ sudo ln -s /usr/local/Cellar/bash /bin/bash 修改完成后输入： 1$ bash --version 出现 12GNU bash, version 4.4.23(1)-release (x86_64-apple-darwin17.5.0)... 大功告成，bash升级成功，于是重启电脑，再次按 cmd + R 进入恢复界面，输入 csrutil enable 打开SIP，再次重启。 此时却没有顺利启动起来，一直卡在登录界面的进度条那里，强制关机、重启也不管用了。查了各种资料，各种方式重启也都不顺利，最后准备重装系统，可惜此时发现系统却没有备份，重装的话有可能丢失数据（这里推荐大家一定要定时及时地进行系统备份，否则到这种时候只有哭的份了），看来也没办法了，强制重装吧。 这个时候突然想到Mac恢复界面是可以使用Terminal的，要不把bash指向改回去试试。于是死马当活马医，重启Mac，再次按 cmd + R 进入恢复界面，进入Terminal： 12$ sudo mv &#x2F;bin&#x2F;bash.origin &#x2F;bin&#x2F;bash$ sudo unlink &#x2F;bin&#x2F;bash 再次重启，竟然复活了，系统完好无损，简直惊险。 到这里，以为bash就这样无法升级了，那也就跟CockroachDB开发无缘了，不过当我在Termina中输入： 1$ bash --version 再次出现： 12GNU bash, version 4.4.23(1)-release (x86_64-apple-darwin17.5.0)... 发现bash已经被改好了，此时算是有惊无险而且结果也是令人满意的。 最后总结两点： 不要随随便便更改系统配置 一定要备份 一定要备份 一定要备份","permalink":"https://txiaozhe.github.io/2018/08/22/bash-mac-error/","photos":[]},{"tags":[{"name":"CockroachDB","slug":"CockroachDB","permalink":"https://txiaozhe.github.io/tags/CockroachDB/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://txiaozhe.github.io/tags/Kubernetes/"}],"title":"在 Kubernetes 集群中运行 CockroachDB","date":"2018/06/10","text":"原文 作者：Alex Robinson 2016年10月11日 [使用说明于2017年1月4日更新] 在Cockroach Labs，我们一直在为更简单地实现用户数据在灾难性错误的情况下保持安全和可用而努力。然而，如果你曾经在是生产环境中负责部署和运维，你就会发现使系统具备高可靠性远不止启动几个进程这么简单，这对于CockroachDB这类具有极强生命力的应用来说也是如此。于是，Kubernetes就有了用武之地。 Kubernetes是一个开源的系统，用于自动化部署，集群扩缩容和容器化应用的管理。这里的 ”容器化“ 即Docker的应用。Kubernetes提供了各种各样的服务，用来实现保持应用程序的正常运行，应用程序复制和更新回滚以及健康检查和日志收集。 如果你熟悉CockroachDB，你就知道它处理了在面对各种故障时以一致的方式复制数据的过程中所有复杂的细节。通过在Kubernetes中运行CockroachDB，我们可以将其内置的副本和生存性模块与Kubernetes的进程管理器匹配，创建一个真正使数据变得简单的高可用系统。 在Kubernetes中进行状态管理如果你有一些Kubernetes的使用经验，你可能会有所质疑，数据库要运行在一个系统上，这个系统的历史中却没有为有状态的集群化应用提供一个很好管理服务。确实，Kubernetes早期阶段主要的目标是无状态的应用（无需管理它们自己的持久数据），但是，Kubernetes背后的团队在今年已经开始致力于以StatefulSet的形式为有状态的应用构建一流的支持。 通常来说，当一个Kubernetes pod（包含经编排的一个或多个容器的运行组）消亡时，它将被一个新的pod所取代，新的pod会包含一个新的标识符，新的IP地址以及主机名。但是，无论这个pod重启多少次甚至改变底层的主机，StatefulSet都可确保每个副本拥有它自己稳定的标识符（通过DNS解析）。这对于CockroachDB来说是很有意义的，因为这意味着每当pod被新副本取代时，我们不再需要像对待集群中的新节点那样对待这个pod，否则这会导致大量的数据复制。这对于高效支持我们的一致性协议和分布式事务是很重要的。 在Kubernetes这样的编排系统中运行像CockroachDB这样的数据库，另一个更明显的问题是如何找出每一个副本的数据存在的位置。不同的存储方式，其相应解决方案的成熟度不同。Kubernetes很早就对‘PersistentVolumes’有了很好的支持，也就是可以挂载在Kubernetes任意节点上的远程磁盘。这是一种很好的策略因为它允许一个副本在不丢失任何数据的情况下迁移。然而，正因为这些数据是远程的（且常常在后台被复制，比如EC2上的EBS卷和Google Compute Engine上的持久卷），这意味着相比于使用本地磁盘，这种方式存在明显的延迟开销。 像CockroachDB这样一个云生和集群化的数据库来说，偶尔出现单台机器上的数据丢失的情况，一点问题都没有，因为它能探测到机器上数据副本不足，从而相应添加副本。正因如此，理想情况下为每个副本使用本地磁盘可以降低延迟。然而，由于一些原因（这些问题已经在1.6release版本中经过了严肃的讨论），Kubernetes目前还不支持StatefulSets使用本地磁盘。在此期间，远程持久卷已经能满足我们的需求。 实现细节：在Kubernetes中运行CockroachDB创建一个Kubernetes集群创建一个Kubernetes集群有很多种不同的方式。为了简单起见我们将使用Container Engine，这在其他环境下也是可行的。例如，参照我们的文档有关如果在本地Minikube中运行或参照Kubernetes 的文档在AWS中创建集群。如果你安装了gcloud，你可以通过运行以下命令来创建集群： 1$ gcloud container clusters create cockroachdb-cluster 快速启动CockroachDBKubernetes的配置使用YAML配置文件进行管理，CockroachDB的配置也不例外。我们可以使用以下配置创建一个集群，其中的注释解释了我们的操作。首先，从我们的Github 仓库中复制名叫cockroachdb-statefulset.yaml的配置文件。这个文件定义了将被创建的Kubernetes资源，包括快速启动CockroachDB 容器的StatefulSet对象并将其连接至持久卷。 然后，创建这些资源，如下（如果你使用Minikube，你可能首先需要手动配置持久卷）。稍后，你将看到在集群中运行的3个副本和一些服务。刚开始，因为副本还没有全部启动，可能只显示一部分的副本。这是正常的，因为StatefulSets会从第一个开始逐个创建副本： 1$ kubectl create -f cockroachdb-statefulset.yaml service “cockroachdb-public” createdservice “cockroachdb” createdpoddisruptionbudget “cockroachdb-budget” createdstatefulset “cockroachdb” created 1$ kubectl get services cockroachdb None 26257/TCP,8080/TCP 4scockroachdb-public 10.0.0.85 26257/TCP,8080/TCP 4skubernetes 10.0.0.1 443/TCP 1h 1$ kubectl get pods NAME READY STATUS RESTARTS AGEcockroachdb-0 1/1 Running 0 29scockroachdb-1 0/1 Running 0 9s 1$ kubectl get pods NAME READY STATUS RESTARTS AGEcockroachdb-0 1/1 Running 0 1mcockroachdb-1 1/1 Running 0 41scockroachdb-2 1/1 Running 0 21s 如果你想看看这个过程中发生了什么，你可以运行kubectl logs cockroachdb-0查看其中一个pod的日志。 使用CockroachDB集群一旦你的集群开始运行了，你一定会想去尝试它。通过Kubernetes打开一个SQL shell，你可以运行一个一次性的pod，并使用cockroachdb-public作为hostname来访问CockroachDB集群。Kubernetes将会自动均衡地将连接分配至健康的CockroachDB实例。 1$ kubectl run cockroachdb -it --image&#x3D;cockroachdb&#x2F;cockroach --rm --restart&#x3D;Never -- sql --insecure --host&#x3D;cockroachdb-public 等待cockroachdb运行成功，此时状态为Pending，pod ready状态为 false 输入如下命令： 12345678910111213root@cockroachdb-public:26257&gt; CREATE DATABASE bank;CREATE DATABASEroot@cockroachdb-public:26257&gt; CREATE TABLE bank.accounts (id INT PRIMARY KEY, balance DECIMAL);CREATE TABLEroot@cockroachdb-public:26257&gt; INSERT INTO bank.accounts VALUES (1234, 10000.50);INSERT 1root@cockroachdb-public:26257&gt; SELECT * FROM bank.accounts;+------+-------------+| id | balance |+------+-------------+| 1234 | 10000.5 |+------+----------+(1 row) 查看管理页面如果你想查看集群的行为信息，你可以通过将你本地机器的端口映射到其中一个pods拉取CockroachDB管理UI： 1$ kubectl port-forward cockroachdb-0 8080 运行了这个命令，你就可以在浏览器中输入http://localhost:8080/来访问管理UI了。 模拟节点故障如果你想测试集群的弹性，你可以尝试在通过SQL shell访问集群的同时，新起一个终端运行类似于kubectl delete pod cockroachdb-3的命令来杀掉一些容器。如果你碰巧删除了你的shell正在操作的实例，你可能偶尔会遇到 bad connection 的错误，但是重试查询操作依然会生效。这些被杀掉的容器将会通过StatefulSet 管理器被重新创建，就像机器在生产环境中宕机一样。 如果你想测试集群中数据的持久性，你也可以尝试一次性删除所有的pod并确保当它们恢复时能正确地从各自的持久化卷中启动。要实现这一点，可以通过运行kubectl delete pod –selector app=cockroachdb以删除所有标签为app=cockroachdb的pod，其中包括来自我们StatefulSet中的pod。所有的pod恢复的过程会花费一点时间（就像创建它们的时候一样），但是一旦它们重启并再次运行，你运行SQL语句时就应该得到相同的结果。 缩放CockroachDB集群Kubernetes使得按需缩放集群变得简单。如果你想为集群添加新的副本，你需要做的就是调整StatefulSet，如下所示： 1$ kubectl scale statefulset cockroachdb --replicas=4 关闭CockroachDB集群如果你想清理所有我们创建的资源，可以通过一条命令，这要归功于我们为所有资源添加的labels: 1$ kubectl delete statefulsets,pods,persistentvolumes,persistentvolumeclaims,services,poddisruptionbudget -l app=cockroachdb 或者，你也可以关闭整个Kubernetes集群： 1$ gcloud container clusters delete cockroachdb-cluster 鉴于目前CockroachDB尚未成熟地产品化，我们现在不建议将此设置应用到关键任务的数据中，但是，但是你仍然可以在机器上做很多事，比如： 使用众多支持CockroachDB 集群的客户端中的一个来开发应用。 修改集群初始化的方式以便在节点之间使用证书进行加密。 在云主机或裸机上而不是在容器引擎中用不同的持久卷起一个集群。 利用我们在CockroachDB StatefulSet中提示的优势搭建Prometheus来监控集群内的CockroachDB。 将构建特征的请求、问题或改进建议提交给CockroachDB、Kubernetes 文档或它的核心数据库。 参考在我们的文档或Github 仓库中可以找到在Kubernetes中运行CockroachDB的最新配置文件等更多信息。","permalink":"https://txiaozhe.github.io/2018/06/10/run-cockroachdb-in-kubernetes/","photos":[]},{"tags":[{"name":"CockroachDB","slug":"CockroachDB","permalink":"https://txiaozhe.github.io/tags/CockroachDB/"},{"name":"Schema","slug":"Schema","permalink":"https://txiaozhe.github.io/tags/Schema/"}],"title":"CockroachDB 是如何让在线Schema Change成为可能的","date":"2018/05/24","text":"我经常需要更改表结构，其中主要是为表添加列。当然这用alter命令很容易就能实现，但是，目前我的表已经达到40,000,000行之多且还在不断地增长，这使得执行alter命令往往需要个把小时。因为我用的是亚马逊的RDS服务，所以我不能用主从的策略来实现。因此我在思考能否做到在最小化的宕机时间条件下做到这一点。当然我也不介意有用户愿意花费几小时甚至几天的时间来进行这样的操作…… ——— 摘自 Stack Overflow 2010年8月26日 serverfault ​ 以上这条提问是在2010年发布的，但是关于进行这种操作问题的焦虑至今却依然存在。 ​ 我们在设计CockroachDB表结构更改引擎的时候总想把它做得更好以提供一个简单的修改表结构的方式(比如只要运行ALTER TABLE命令就可以)使得应用不需要承担宕机带来的任何负面后果。我们也希望更改表结构是CockroachDB的一项内置功能而不需要任何外界工具、资源或特定的操作步骤来支持且对应用程序的读写没有任何影响。 ​ 我将用以下的篇幅来解释我们在线更改表结构方案的机制并讨论在不宕机的前提下对结构元素(如列和索引)的更改。 我们做了什么​ 更改表结构通常涉及到更改结构本身和随着结构的更改而增加或删除的数据关系，而分布式数据库的两个基本特性使得这一点实现起来并不那么容易： 高性能：为了优化数据库性能，表结构必须缓存跨库节点，而维护分布式缓存的一致性往往是非常困难的 大表：分布式数据库中的表往往非常巨大，与表结构更改相关的任何表数据的回填或删除都将花费一定时间，要在不禁用数据库访问的前提下实现这一点也非常困难 ​ 对于第一个问题，我们给出的解决方案包括使用版本化的结构，并允许在旧版本结构仍在使用的情况下发布新的结构和对大表支持在不加锁的情况下回填(或删除)表数据。这个解决方案由谷歌的F1团队在工作中总结得出。 创建安全结构​ 和表结构元素(可以是索引或列，但在本文的剩余部分中我们将着重关注索引)相关联的数据都可以通过SQL DML命令删除或读写(比如 INSERT, UPDATE, DELETE, SELECT)。CockroachDB使用的策略是建立新索引时逐个而非同时地对其赋予以上命令描述的删除和读写权限。 因此，建立一个新索引需遵循以下步骤： 赋予删除权限 赋予写权限 回填索引数据 赋予读权限 ​ 在新的结构中，新授予的权限将与旧版本中已赋予的权限一起被授予。为了保证正确性，一种新的权限在只有当整个集群都使用包含所有已赋予权限的结构时的情况下才能被赋予，因此，整个过程将在每一步执行前暂停并允许在下一项权限赋予前将已赋予的权限应用到整个集群。 删除索引时也同样需要遵循相应的步骤： 吊销读权限 吊销写权限 清除索引数据 吊销删除权限 ​ 同样，一种操作权限被吊销时也需确保整个集群对已赋予的权限进行了同样的操作。 删除操作权限：避免虚假索引条目​ 当某位置建立了DELETE_ONLY状态的索引时即赋予这种权限，具有这种权限的SQL DML命令具有自我约束的特性： DELETE：这种删除操作将完全作用于该索引所涉及到的行和基础索引数据 UPDATE：会删除旧的索引条目，并限制自身不会写入新的索引条目 INSERT 和 SELECT 会忽略索引 ​ 在下一阶段中对索引被赋予写权限的节点将信任整个集群使用索引的删除权限。也就是说，当节点收到一个INSERT命令需要为一行数据插入索引条目时，另一个只拥有删除权限的节点在收到针对相同行的DELETE命令时会准确地删除该行的索引，这个索引将避免因悬空索引而出错。 ​ 另外，当删除索引时，相关的索引数据也仅在写入权限被集群回收后才会被删除，并且也只有当集群拥有删除能力时才允许其进行安全的删除操作。 写入权限：避免丢失索引条目​ 当某位置建立了WRITE_AND_DELETE_ONLY状态的索引时随即赋予这种同时具有删除和写入的权限： INSERT，UPDATE和 DELETE 命令都正常运行，并按需添加或删除索引项 SELECT 命令需要读取权限因而会忽略索引 ​ 索引回填仅在整个集群都可写入时才可以运行。在回填过程中，任何节点上接收到的 INSERT 命令都将创建一个带有合法索引项的新行，并且不依赖单独的回填过程来为该行创建索引项。如此一来，可以保证直整个过程都不会丢失索引项。 读权限​ 最后一个权限是通过索引激活来赋予的，并且可以被所有命令完全使用。 快速的表结构迭代​ 在表结构更改的每一个阶段中都将允许整个集群的表结构向最新版本看齐。一般的表结构缓存机制都使用5分钟的存活时间，这也导致在修改进程信任最新版本的表结构是独有的且操作能力被完全赋予或吊销之前被强制要求等待几分钟。在CockroachDB中，我们开发了表结构版本的租约来加速集群表结构更新到最新版本以加快表结构更新的进程。 ​ 当要对表进行SQL DML命令操作时，运行该命令的节点会获取一个具有有效时间(以分钟为单位)的读取租约。被更改了的表结构版本被激活的消息会被广播到整个集群以通知节点更新到新的版本并主动释放旧版本的租约，此时如果一些不健康的节点未能主动释放，迭代机制将等待租约的过期以及延期迭代。 ​ 租约机制通过遵循以下两个规则使得表结构更改策略更简单： 最新的结构版本才可以签发新租约 有效的租约只存在于最新的两个版本之内 有关表租约更详细的讨论请在我们的Github 库的文档中查看。 准确可靠的表结构迭代​ 表结构的更改由节点执行的相关SQL命令来引导完成，这个过程往往耗费较长时间，假如过程中节点宕机则需要重启整个过程。每个节点也都会运行一个能执行任何不完整的结构更改过程的协程，在更改结构过程运行前，这个协程会获取相关表的一个独有的写入租约，这也是唯一可以引导更改成功的许可证。 小结​ 在线表结构的更改操作在CockroachDB中非常容易实现并且安全、快速、可靠。改变是不可避免的，而现在你再也不必担心了！ ​ 在此感谢谷歌F1团队发布的在线表结构更改的类似实现，我们从中也获得了很多灵感。","permalink":"https://txiaozhe.github.io/2018/05/24/schema-change/","photos":[]},{"tags":[{"name":"GitHub","slug":"GitHub","permalink":"https://txiaozhe.github.io/tags/GitHub/"}],"title":"记一次 GitHub 的惊险历程","date":"2017/07/27","text":"今天得空重新部署了一下GitHub博客，换了新的主题和布局，感觉一切都焕然一新。 ​ 我原本是有一个GitHub博客的，第一次部署花了很长时间，各种奇怪的错误，各种坑，但最后也部署成功了，而且因为做过一段时间前端，所以除了框架里给的主题，也按照自己的想法换了一些风格，当时是很有成就感的。也断断续续地往上添了一些内容，Docker、移动端、前端开发等。但后来又来了新项目，时间也逐渐被工作占满，也渐渐地遗忘还有一个博客孤单的跑在GitHub上，直到前几天…… ​ 就在这周二，也就是2017年7月25日，早上，我和往常一样来到公司，打开电脑，因为公司内部所有项目都是基于GitHub平台进行管理的，而且有几个项目还是交由我来管理的，因此习惯性地点开GitHub主页查看项目进度。但是奇怪，平常很快就能登录的GitHub这次却怎么也无法登录，因为用的是Chrome浏览器因此能记住密码，连续点了几次登录依然无法成功，接着又开始怀疑是密码错误，反复试了密码都提示账号或密码错误。这时候突然有人喊：你的那个商城的项目不见了！！！我顿时慌了，查看另外几个项目也都消失了，最后在GitHub搜索框里搜索我的用户名也没有结果，紧接着查看了一下与GitHub账户绑定的Gmail，就看到了这样一封邮件： This email is to confirm that you’ve deleted your account ‘Txiaozhe’ from GitHub. Your repositories and content have been deleted from the system. If you were on a paid plan, you will not be billed again. We’re sorry to see you go. You can reply directly to this email if you have any questions or feedback, we’d love to hear from you. 我的天，我的GitHub竟然被删除了！！！从邮件里看还是被我自己删除的！！！当时第一反应就是GitHub账户被黑了，一定是某人登陆了我的账户并删除账户。这个杀千刀的。当时已经是上班时间，大家基本都到了，得知这个消息后突然都变得很恐慌，连忙查看自己账户是否也有问题。而彼时彼刻，我的内心更是心痛万分，2015年申请的GitHub账户，到现在已经两年多了，项目数、提交数、star数都有一点积累，特别是最近一年，而这一次被删除意味着这些努力都白费了，辛辛苦苦写的代码，本地也只备份了一小部分，那些没备份的都消失了。 ​ 等心情平复了一些，慢慢地也就接受了现实，想着其实之前写的代码里也是有很多垃圾代码的，正好趁着这次机会重构一下，同时也总结之前做的事。重新申请了GitHub账户，把之前本地备份过的代码也都重新上传，看着新的账户里的内容逐渐丰富起来，也算是有了一点点安慰。同时，为了防范再次出现这类事件，公司要求所有人的GitHub账户都必须设置二步验证，阅读过这篇博客的读者也可以尝试设置二步验证以加强账户安全。 ​ 第二天的时候，事情突然有了转机。有一个同事在搜索我的用户名的时候偶然间发现我原来的用户名又出现了，紧接着就确认，我的账户又恢复了！我重新登陆了一下原来的账户，果然又能登陆了，而且里面的项目都恢复了！这算是惊喜吗？我和同事们开玩笑，人生的大起大落也不过如此！再看看Gmail，突然又多了几封邮件，打开看看，原来是GitHub的工作人员发来的，邮件就不展示了，主要内容就是各种道歉，原来是他们的员工操作失误将我的代码库删除了，而且因祸得福，为了弥补我，他们打算赠送我一件GitHub主题的T恤和6个月的私有库账户权限，并很及时地恢复了账户中的错误，在此也非常感谢GitHub的工作人员 Chris 、Michael 和 Jonathan Hoyt 帮我解决了问题。 ​ 过了3天了，回想起来从最开始的痛心，紧接着平复到最后得到补偿竟然还有点惊喜，整个历程可谓跌宕起伏。最后不足的是其他都恢复了，但还有部分提交记录和GitHub博客没恢复，提交记录基本认命了，但博客还是可以重新打造的，也算是脱胎换骨了，仅以记录了这次事件的文章作为新博客的开篇，也算是留个纪念了！","permalink":"https://txiaozhe.github.io/2017/07/27/github-adjective/","photos":[]},{"tags":[{"name":"OAuth","slug":"OAuth","permalink":"https://txiaozhe.github.io/tags/OAuth/"},{"name":"JWT","slug":"JWT","permalink":"https://txiaozhe.github.io/tags/JWT/"}],"title":"常用鉴权方式和JWT简介","date":"2017/07/24","text":"常用的认证HTTP Basic Auth 每次请求时都提供用户名和密码，是最简单的认证方式 有把用户名密码暴露给第三方的风险，因此生产环境下越来越少地被使用 OAuth（开放授权） 允许第三方应用访问该用户在某一web服务器上存储的私密的资源，无需将用户名密码提供给第三方 用户提供一个令牌而非用户名密码来访问特定服务提供者的数据 适用于个人消费类的互联网产品，如社交App（微信），但不适合拥有自有认证权限管理的企业应用 Cookie Auth &amp; Token Auth Token Auth的优点 支持跨域访问：Cookie不支持跨域访问，当用户认证信息通过HTTP头传输时Token允许跨域访问 无状态：Token自身包含了所有登录用户的信息，只需要在客户端存储相关信息而不需要在服务端存储 更适用于CDN（内容分发网络）：可以通过内容分发网络请求服务端的所有资料 去耦：不需要绑定到特定的身份验证方案，可在任何地方生成Token 更适用于移动平台：原生平台不支持cookie，因此适合采用Token 无需考虑CSRF（跨站请求伪造）：因不依赖cookie，因此无需考虑该安全问题 性能：一次网络往返时间（通过数据库查询session信息）比做一次Token验证和解析要费时的多 标准化库：可采用JWT标准的库，生态支持良好 基于jwt的Token认证机制实现JWT 的组成Token是一个字符串，由三部分组成：头部、载荷、签名 载荷(Payload)： 1234567891011&#123; \"iss\": \"Online JWT Builder\", \"iat\": 1416797419, \"exp\": 1448333419, \"aud\": \"www.example.com\", \"sub\": \"jrocket@example.com\", \"GivenName\": \"Johnny\", \"Surname\": \"Rocket\", \"Email\": \"jrocket@example.com\", \"Role\": [ \"Manager\", \"Project Administrator\" ]&#125; iss：JWT签发者，可选 sub：JWT面向的用户，可选 aud：接收该JWT的一方，可选 exp（expires）：过期时间，时间戳，可选 iat（issued at）：签发时间，可选 将上面的json进行base64编码得到一下字符串，称为Payload： 1eyJpc3MiOiJKb2huIFd1IEpXVCIsImlhdCI6MTQ0MTU5MzUwMiwiZXhwIjoxNDQxNTk0NzIyLCJhdWQiOiJ3d3cuZXhhbXBsZS5jb20iLCJzdWIiOiJqcm9ja2V0QGV4YW1wbGUuY29tIiwiZnJvbV91c2VyIjoiQiIsInRhcmdldF91c2VyIjoiQSJ9 Base64是一种基于64个可打印字符来表示二进制数据的表示方法。由于2的6次方等于64，所以每6个比特为一个单元，对应某个可打印字符。三个字节有24个比特，对应于4个Base64单元，即3个字节需要用4个可打印字符来表示 头部(Header)：描述该jwt最基本的信息 1234&#123; \"typ\": \"JWT\", \"alg\": \"HS256\"&#125; alg：签名算法（必选，其他都是可选） typ: 类型 （如果是 JWT 那么就带有一个值 JWT） *kid: * 密钥 ID cty: 内容类型 jku: JWK 指定 URL jwk: JSON 网络值 x5u: X.509 URL *x5c: * X.509 证书链 x5t: X.509 证书 SHA-1 指纹 x5t#S256: X.509 证书 SHA-256 指纹 crit: 临界值 将该头部也进行base64转换，得到如下字符串： 1eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9 签名（Signature）： 将上面的两个编码后的字符串都用句号.连接在一起（Header在前），就形成了: 1eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJKb2huIFd1IEpXVCIsImlhdCI6MTQ0MTU5MzUwMiwiZXhwIjoxNDQxNTk0NzIyLCJhdWQiOiJ3d3cuZXhhbXBsZS5jb20iLCJzdWIiOiJqcm9ja2V0QGV4YW1wbGUuY29tIiwiZnJvbV91c2VyIjoiQiIsInRhcmdldF91c2VyIjoiQSJ9 最后，将上面拼接完的字符串用HS256算法进行加密。在加密的时候，我们还需要提供一个密钥（secret）。比如用mystar作为密钥，加密后的内容: 1rSWamyAYwuHCo7IFAgd1oRpSP7nzL7BF5t7ItqpKViM 最终的Token： 1eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJKb2huIFd1IEpXVCIsImlhdCI6MTQ0MTU5MzUwMiwiZXhwIjoxNDQxNTk0NzIyLCJhdWQiOiJ3d3cuZXhhbXBsZS5jb20iLCJzdWIiOiJqcm9ja2V0QGV4YW1wbGUuY29tIiwiZnJvbV91c2VyIjoiQiIsInRhcmdldF91c2VyIjoiQSJ9.rSWamyAYwuHCo7IFAgd1oRpSP7nzL7BF5t7ItqpKViM Token认证过程： 第一次登录，用户从浏览器输入用户名/密码，提交后到服务器的登录处理的Login Action层 Login Action调用认证服务进行用户名密码认证，如果认证通过，Login Action层调用用户信息服务获取用户信息（包括完整的用户信息及对应权限信息） 返回用户信息后，Login Action从配置文件中获取Token签名生成的秘钥信息，进行Token的生成； 生成Token的过程中可以调用第三方的JWT Lib生成签名后的JWT数据 完成JWT数据签名后，将其设置到COOKIE对象中，并重定向到首页，完成登录过程 请求认证 基于Token的认证机制会在每一次请求中都带上完成签名的Token信息，这个Token信息可能在COOKIE中，也可能在HTTP的Authorization头中 客户端（APP客户端或浏览器）通过GET或POST请求访问资源 认证服务作为一个Middleware HOOK 对请求进行拦截，首先在cookie中查找Token信息，如果没有找到，则在HTTP Authorization Head中查找 如果找到Token信息，则根据配置文件中的签名加密秘钥调用JWT Lib对Token信息进行解密和解码 完成解码并验证签名通过后，对Token中的exp、nbf、aud等信息进行验证 全部通过后，根据获取的用户的角色权限信息，进行对请求的资源的权限逻辑判断 如果权限逻辑判断通过则通过Response返回给客户端 使用Token Oauth 需要注意的地方 一个Token就是一些信息的集合，因此可以在Token中包含足够多的信息，以便在后续请求中减少查询数据库的几率，其中的机密信息应加密后再存入 服务端需要对cookie和HTTP Authrorization Header进行Token信息的检查，因此可以用一套token认证代码来面对浏览器类客户端和非浏览器类客户端 因为token是被签名的，所以我们可以认为一个可以解码认证通过的token是由我们系统发放的，其中带的信息是合法有效的 通过JWT登出因为没有 session 数据存储在服务端所以不能再通过破坏 session 来注销用户。因此登出成为了客户端的职责 - 一旦客户丢失了令牌不能再被授权，就可以被认为是登出了","permalink":"https://txiaozhe.github.io/2017/07/24/auth/","photos":[]}]}